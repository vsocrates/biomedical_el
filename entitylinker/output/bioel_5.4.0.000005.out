Restoring modules from user's fosscuda111, for system: "farnam-rhel7"
/home/vs428/project/MedMentions/full/pretraining5/entity_vocab.jsonl
Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
0
<torch.cuda.device object at 0x2b4f1d2c8b20>
1
GeForce GTX 1080 Ti
[1,     5] train loss: 1.005
[1,    10] train loss: 1.007
[1,    15] train loss: 1.007
[1,    20] train loss: 1.005
[1,    25] train loss: 1.001
[1,    30] train loss: 1.000
[1,    35] train loss: 1.003
[1,    40] train loss: 1.001
[1,    45] train loss: 1.000
[1,    50] train loss: 0.999
[1,    55] train loss: 0.993
[1,    60] train loss: 0.989
[1,    65] train loss: 1.000
[1,    70] train loss: 0.994
[1,    75] train loss: 0.995
[1,    80] train loss: 0.992
[1,    85] train loss: 0.995
[1,    90] train loss: 0.993
[1,    95] train loss: 0.990
[1,   100] train loss: 0.989
[1,   105] train loss: 0.987
[1,   110] train loss: 0.986
[1,   115] train loss: 0.984
[1,   120] train loss: 0.986
[1,   125] train loss: 0.991
[1,   130] train loss: 0.982
[1,   135] train loss: 0.980
[1,   140] train loss: 0.979
[1,   145] train loss: 0.990
[1,   150] train loss: 0.992
[1,   155] train loss: 0.985
[1,   160] train loss: 0.982
[1,   165] train loss: 0.984
[1,   170] train loss: 0.984
[1,   175] train loss: 0.975
[1,   180] train loss: 0.968
[1,   185] train loss: 0.977
[1,   190] train loss: 0.980
[1,   195] train loss: 0.977
[1,   200] train loss: 0.977
[1,   205] train loss: 0.975
[1,   210] train loss: 0.973
[1,   215] train loss: 0.974
[1,   220] train loss: 0.965
[1,   225] train loss: 0.959
[1,   230] train loss: 0.972
[1,   235] train loss: 0.969
[1,   240] train loss: 0.966
[1,   245] train loss: 0.969
[1,   250] train loss: 0.964
[1,   255] train loss: 0.968
[1,   260] train loss: 0.965
[1,   265] train loss: 0.959
[1,   270] train loss: 0.957
[1,   275] train loss: 0.955
[1,   280] train loss: 0.954
[1,   285] train loss: 0.951
[1,   290] train loss: 0.953
[1,   295] train loss: 0.951
[1,   300] train loss: 0.941
[1,   305] train loss: 0.954
[1,   310] train loss: 0.948
[1,   315] train loss: 0.954
[1,   320] train loss: 0.945
[1,   325] train loss: 0.951
[1,   330] train loss: 0.945
[1,   335] train loss: 0.951
[1,   340] train loss: 0.945
[1,   345] train loss: 0.945
[1,   350] train loss: 0.945
[1,   355] train loss: 0.943
[1,   360] train loss: 0.939
[1,   365] train loss: 0.942
[1,   370] train loss: 0.937
[1,   375] train loss: 0.937
[1,   380] train loss: 0.932
[1,   385] train loss: 0.943
[1,   390] train loss: 0.941
[1,   395] train loss: 0.938
[1,   400] train loss: 0.938
[1,   405] train loss: 0.941
[1,   410] train loss: 0.926
[1,   415] train loss: 0.940
[1,   420] train loss: 0.927
[1,   425] train loss: 0.936
[1,   430] train loss: 0.937
[1,   435] train loss: 0.925
[1,   440] train loss: 0.942
[1,   445] train loss: 0.927
[1,   450] train loss: 0.931
[1,   455] train loss: 0.931
[1,   460] train loss: 0.928
[1,   465] train loss: 0.927
[1,   470] train loss: 0.929
[1,   475] train loss: 0.931
[1,   480] train loss: 0.927
[1,   485] train loss: 0.917
[1,   490] train loss: 0.928
[1,   495] train loss: 0.927
[1,   500] train loss: 0.925
[1,   505] train loss: 0.923
[1,   510] train loss: 0.927
[1,   515] train loss: 0.929
[1,   520] train loss: 0.924
[1,   525] train loss: 0.924
[1,   530] train loss: 0.925
[1,   535] train loss: 0.918
[1,   540] train loss: 0.916
[1,   545] train loss: 0.925
[1,   550] train loss: 0.913
[1,   555] train loss: 0.911
[1,   560] train loss: 0.915
[1,   565] train loss: 0.927
[1,   570] train loss: 0.914
[1,   575] train loss: 0.911
[1,   580] train loss: 0.906
[1,   585] train loss: 0.923
[1,   590] train loss: 0.913
[1,   595] train loss: 0.908
[1,   600] train loss: 0.910
[1,   605] train loss: 0.912
[1,   610] train loss: 0.908
[1,   615] train loss: 0.913
[1,   620] train loss: 0.909
[1,   625] train loss: 0.892
[1,   630] train loss: 0.899
[1,   635] train loss: 0.907
[1,   640] train loss: 0.906
[1,   645] train loss: 0.894
[1,   650] train loss: 0.916
[1,   655] train loss: 0.911
Finished Training
[1,     5] test loss: 0.903
[1,    10] test loss: 0.895
[1,    15] test loss: 0.891
[1,    20] test loss: 0.910
[1,    25] test loss: 0.899
[1,    30] test loss: 0.904
[1,    35] test loss: 0.893
[1,    40] test loss: 0.902
[1,    45] test loss: 0.893
[1,    50] test loss: 0.899
[1,    55] test loss: 0.903
[1,    60] test loss: 0.894
[1,    65] test loss: 0.897
[1,    70] test loss: 0.910
[1,    75] test loss: 0.906
[1,    80] test loss: 0.898
[1,    85] test loss: 0.900
[1,    90] test loss: 0.900
[1,    95] test loss: 0.889
[1,   100] test loss: 0.901
[1,   105] test loss: 0.899
[1,   110] test loss: 0.897
[1,   115] test loss: 0.898
[1,   120] test loss: 0.902
[1,   125] test loss: 0.900
[1,   130] test loss: 0.898
[1,   135] test loss: 0.893
[1,   140] test loss: 0.894
[1,   145] test loss: 0.887
[1,   150] test loss: 0.897
[1,   155] test loss: 0.898
[1,   160] test loss: 0.891
[1,   165] test loss: 0.889
[1,   170] test loss: 0.891
[1,   175] test loss: 0.906
[1,   180] test loss: 0.900
[1,   185] test loss: 0.900
[1,   190] test loss: 0.903
[1,   195] test loss: 0.894
[1,   200] test loss: 0.906
[1,   205] test loss: 0.888
[1,   210] test loss: 0.906
[1,   215] test loss: 0.891
[1,   220] test loss: 0.910
-----------------------------------------------------------------------------------------
Micro-Precision: 0.02864629030227661, Macro-Precision: nan

Micro-Recall: 0.031035996973514557, Macro-Recall: nan

Micro-F1: 0.029793301597237587, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   0 | time: 151.39s | valid loss  0.90 | valid ppl     2.47
-----------------------------------------------------------------------------------------
[2,     5] train loss: 0.908
[2,    10] train loss: 0.900
[2,    15] train loss: 0.910
[2,    20] train loss: 0.901
[2,    25] train loss: 0.912
[2,    30] train loss: 0.905
[2,    35] train loss: 0.899
[2,    40] train loss: 0.893
[2,    45] train loss: 0.897
[2,    50] train loss: 0.902
[2,    55] train loss: 0.908
[2,    60] train loss: 0.888
[2,    65] train loss: 0.895
[2,    70] train loss: 0.901
[2,    75] train loss: 0.895
[2,    80] train loss: 0.899
[2,    85] train loss: 0.904
[2,    90] train loss: 0.902
[2,    95] train loss: 0.897
[2,   100] train loss: 0.896
[2,   105] train loss: 0.898
[2,   110] train loss: 0.901
[2,   115] train loss: 0.885
[2,   120] train loss: 0.897
[2,   125] train loss: 0.888
[2,   130] train loss: 0.890
[2,   135] train loss: 0.884
[2,   140] train loss: 0.890
[2,   145] train loss: 0.899
[2,   150] train loss: 0.898
[2,   155] train loss: 0.883
[2,   160] train loss: 0.890
[2,   165] train loss: 0.897
[2,   170] train loss: 0.883
[2,   175] train loss: 0.892
[2,   180] train loss: 0.884
[2,   185] train loss: 0.893
[2,   190] train loss: 0.877
[2,   195] train loss: 0.888
[2,   200] train loss: 0.890
[2,   205] train loss: 0.897
[2,   210] train loss: 0.883
[2,   215] train loss: 0.887
[2,   220] train loss: 0.898
[2,   225] train loss: 0.878
[2,   230] train loss: 0.882
[2,   235] train loss: 0.889
[2,   240] train loss: 0.896
[2,   245] train loss: 0.892
[2,   250] train loss: 0.880
[2,   255] train loss: 0.877
[2,   260] train loss: 0.889
[2,   265] train loss: 0.894
[2,   270] train loss: 0.885
[2,   275] train loss: 0.891
[2,   280] train loss: 0.881
[2,   285] train loss: 0.890
[2,   290] train loss: 0.884
[2,   295] train loss: 0.890
[2,   300] train loss: 0.889
[2,   305] train loss: 0.878
[2,   310] train loss: 0.885
[2,   315] train loss: 0.881
[2,   320] train loss: 0.887
[2,   325] train loss: 0.887
[2,   330] train loss: 0.895
[2,   335] train loss: 0.875
[2,   340] train loss: 0.881
[2,   345] train loss: 0.876
[2,   350] train loss: 0.882
[2,   355] train loss: 0.890
[2,   360] train loss: 0.877
[2,   365] train loss: 0.874
[2,   370] train loss: 0.875
[2,   375] train loss: 0.895
[2,   380] train loss: 0.891
[2,   385] train loss: 0.873
[2,   390] train loss: 0.894
[2,   395] train loss: 0.890
[2,   400] train loss: 0.886
[2,   405] train loss: 0.889
[2,   410] train loss: 0.886
[2,   415] train loss: 0.869
[2,   420] train loss: 0.895
[2,   425] train loss: 0.865
[2,   430] train loss: 0.877
[2,   435] train loss: 0.883
[2,   440] train loss: 0.868
[2,   445] train loss: 0.887
[2,   450] train loss: 0.893
[2,   455] train loss: 0.877
[2,   460] train loss: 0.884
[2,   465] train loss: 0.882
[2,   470] train loss: 0.901
[2,   475] train loss: 0.865
[2,   480] train loss: 0.878
[2,   485] train loss: 0.884
[2,   490] train loss: 0.872
[2,   495] train loss: 0.873
[2,   500] train loss: 0.874
[2,   505] train loss: 0.878
[2,   510] train loss: 0.872
[2,   515] train loss: 0.881
[2,   520] train loss: 0.878
[2,   525] train loss: 0.889
[2,   530] train loss: 0.861
[2,   535] train loss: 0.866
[2,   540] train loss: 0.869
[2,   545] train loss: 0.874
[2,   550] train loss: 0.855
[2,   555] train loss: 0.871
[2,   560] train loss: 0.866
[2,   565] train loss: 0.884
[2,   570] train loss: 0.864
[2,   575] train loss: 0.873
[2,   580] train loss: 0.865
[2,   585] train loss: 0.870
[2,   590] train loss: 0.862
[2,   595] train loss: 0.854
[2,   600] train loss: 0.873
[2,   605] train loss: 0.876
[2,   610] train loss: 0.887
[2,   615] train loss: 0.860
[2,   620] train loss: 0.867
[2,   625] train loss: 0.867
[2,   630] train loss: 0.863
[2,   635] train loss: 0.874
[2,   640] train loss: 0.865
[2,   645] train loss: 0.881
[2,   650] train loss: 0.858
[2,   655] train loss: 0.872
Finished Training
[2,     5] test loss: 0.854
[2,    10] test loss: 0.852
[2,    15] test loss: 0.849
[2,    20] test loss: 0.874
[2,    25] test loss: 0.851
[2,    30] test loss: 0.845
[2,    35] test loss: 0.848
[2,    40] test loss: 0.850
[2,    45] test loss: 0.867
[2,    50] test loss: 0.862
[2,    55] test loss: 0.857
[2,    60] test loss: 0.846
[2,    65] test loss: 0.853
[2,    70] test loss: 0.857
[2,    75] test loss: 0.855
[2,    80] test loss: 0.835
[2,    85] test loss: 0.836
[2,    90] test loss: 0.863
[2,    95] test loss: 0.849
[2,   100] test loss: 0.855
[2,   105] test loss: 0.845
[2,   110] test loss: 0.840
[2,   115] test loss: 0.882
[2,   120] test loss: 0.871
[2,   125] test loss: 0.848
[2,   130] test loss: 0.848
[2,   135] test loss: 0.842
[2,   140] test loss: 0.844
[2,   145] test loss: 0.864
[2,   150] test loss: 0.858
[2,   155] test loss: 0.854
[2,   160] test loss: 0.843
[2,   165] test loss: 0.872
[2,   170] test loss: 0.852
[2,   175] test loss: 0.853
[2,   180] test loss: 0.865
[2,   185] test loss: 0.843
[2,   190] test loss: 0.849
[2,   195] test loss: 0.846
[2,   200] test loss: 0.860
[2,   205] test loss: 0.870
[2,   210] test loss: 0.881
[2,   215] test loss: 0.853
[2,   220] test loss: 0.849
-----------------------------------------------------------------------------------------
Micro-Precision: 0.07609391957521439, Macro-Precision: nan

Micro-Recall: 0.07995551824569702, Macro-Recall: nan

Micro-F1: 0.07797693461179733, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 157.67s | valid loss  0.86 | valid ppl     2.36
-----------------------------------------------------------------------------------------
[3,     5] train loss: 0.874
[3,    10] train loss: 0.883
[3,    15] train loss: 0.872
[3,    20] train loss: 0.857
[3,    25] train loss: 0.862
[3,    30] train loss: 0.866
[3,    35] train loss: 0.873
[3,    40] train loss: 0.863
[3,    45] train loss: 0.857
[3,    50] train loss: 0.881
[3,    55] train loss: 0.856
[3,    60] train loss: 0.870
[3,    65] train loss: 0.880
[3,    70] train loss: 0.860
[3,    75] train loss: 0.865
[3,    80] train loss: 0.874
[3,    85] train loss: 0.858
[3,    90] train loss: 0.845
[3,    95] train loss: 0.863
[3,   100] train loss: 0.864
[3,   105] train loss: 0.851
[3,   110] train loss: 0.852
[3,   115] train loss: 0.866
[3,   120] train loss: 0.859
[3,   125] train loss: 0.863
[3,   130] train loss: 0.854
[3,   135] train loss: 0.863
[3,   140] train loss: 0.855
[3,   145] train loss: 0.874
[3,   150] train loss: 0.860
[3,   155] train loss: 0.867
[3,   160] train loss: 0.861
[3,   165] train loss: 0.867
[3,   170] train loss: 0.871
[3,   175] train loss: 0.847
[3,   180] train loss: 0.829
[3,   185] train loss: 0.862
[3,   190] train loss: 0.841
[3,   195] train loss: 0.847
[3,   200] train loss: 0.865
[3,   205] train loss: 0.850
[3,   210] train loss: 0.872
[3,   215] train loss: 0.843
[3,   220] train loss: 0.868
[3,   225] train loss: 0.859
[3,   230] train loss: 0.838
[3,   235] train loss: 0.862
[3,   240] train loss: 0.842
[3,   245] train loss: 0.851
[3,   250] train loss: 0.854
[3,   255] train loss: 0.855
[3,   260] train loss: 0.846
[3,   265] train loss: 0.849
[3,   270] train loss: 0.857
[3,   275] train loss: 0.850
[3,   280] train loss: 0.864
[3,   285] train loss: 0.845
[3,   290] train loss: 0.868
[3,   295] train loss: 0.860
[3,   300] train loss: 0.853
[3,   305] train loss: 0.871
[3,   310] train loss: 0.853
[3,   315] train loss: 0.862
[3,   320] train loss: 0.863
[3,   325] train loss: 0.842
[3,   330] train loss: 0.849
[3,   335] train loss: 0.857
[3,   340] train loss: 0.849
[3,   345] train loss: 0.859
[3,   350] train loss: 0.864
[3,   355] train loss: 0.843
[3,   360] train loss: 0.855
[3,   365] train loss: 0.858
[3,   370] train loss: 0.853
[3,   375] train loss: 0.851
[3,   380] train loss: 0.866
[3,   385] train loss: 0.848
[3,   390] train loss: 0.839
[3,   395] train loss: 0.842
[3,   400] train loss: 0.854
[3,   405] train loss: 0.856
[3,   410] train loss: 0.841
[3,   415] train loss: 0.841
[3,   420] train loss: 0.862
[3,   425] train loss: 0.861
[3,   430] train loss: 0.854
[3,   435] train loss: 0.835
[3,   440] train loss: 0.845
[3,   445] train loss: 0.834
[3,   450] train loss: 0.847
[3,   455] train loss: 0.847
[3,   460] train loss: 0.861
[3,   465] train loss: 0.849
[3,   470] train loss: 0.845
[3,   475] train loss: 0.844
[3,   480] train loss: 0.844
[3,   485] train loss: 0.856
[3,   490] train loss: 0.831
[3,   495] train loss: 0.844
[3,   500] train loss: 0.843
[3,   505] train loss: 0.845
[3,   510] train loss: 0.840
[3,   515] train loss: 0.855
[3,   520] train loss: 0.834
[3,   525] train loss: 0.836
[3,   530] train loss: 0.852
[3,   535] train loss: 0.841
[3,   540] train loss: 0.827
[3,   545] train loss: 0.837
[3,   550] train loss: 0.840
[3,   555] train loss: 0.838
[3,   560] train loss: 0.837
[3,   565] train loss: 0.837
[3,   570] train loss: 0.855
[3,   575] train loss: 0.838
[3,   580] train loss: 0.856
[3,   585] train loss: 0.822
[3,   590] train loss: 0.817
[3,   595] train loss: 0.844
[3,   600] train loss: 0.837
[3,   605] train loss: 0.828
[3,   610] train loss: 0.833
[3,   615] train loss: 0.829
[3,   620] train loss: 0.840
[3,   625] train loss: 0.849
[3,   630] train loss: 0.851
[3,   635] train loss: 0.853
[3,   640] train loss: 0.832
[3,   645] train loss: 0.839
[3,   650] train loss: 0.826
[3,   655] train loss: 0.836
Finished Training
[3,     5] test loss: 0.823
[3,    10] test loss: 0.820
[3,    15] test loss: 0.812
[3,    20] test loss: 0.819
[3,    25] test loss: 0.822
[3,    30] test loss: 0.829
[3,    35] test loss: 0.822
[3,    40] test loss: 0.821
[3,    45] test loss: 0.840
[3,    50] test loss: 0.829
[3,    55] test loss: 0.837
[3,    60] test loss: 0.821
[3,    65] test loss: 0.807
[3,    70] test loss: 0.827
[3,    75] test loss: 0.824
[3,    80] test loss: 0.827
[3,    85] test loss: 0.814
[3,    90] test loss: 0.806
[3,    95] test loss: 0.837
[3,   100] test loss: 0.809
[3,   105] test loss: 0.818
[3,   110] test loss: 0.823
[3,   115] test loss: 0.803
[3,   120] test loss: 0.819
[3,   125] test loss: 0.827
[3,   130] test loss: 0.816
[3,   135] test loss: 0.833
[3,   140] test loss: 0.828
[3,   145] test loss: 0.809
[3,   150] test loss: 0.826
[3,   155] test loss: 0.825
[3,   160] test loss: 0.821
[3,   165] test loss: 0.835
[3,   170] test loss: 0.818
[3,   175] test loss: 0.824
[3,   180] test loss: 0.844
[3,   185] test loss: 0.803
[3,   190] test loss: 0.829
[3,   195] test loss: 0.834
[3,   200] test loss: 0.836
[3,   205] test loss: 0.834
[3,   210] test loss: 0.834
[3,   215] test loss: 0.825
[3,   220] test loss: 0.814
-----------------------------------------------------------------------------------------
Micro-Precision: 0.11654076725244522, Macro-Precision: nan

Micro-Recall: 0.1313948780298233, Macro-Recall: nan

Micro-F1: 0.12352285534143448, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 159.13s | valid loss  0.83 | valid ppl     2.29
-----------------------------------------------------------------------------------------
[4,     5] train loss: 0.825
[4,    10] train loss: 0.835
[4,    15] train loss: 0.831
[4,    20] train loss: 0.818
[4,    25] train loss: 0.824
[4,    30] train loss: 0.839
[4,    35] train loss: 0.847
[4,    40] train loss: 0.836
[4,    45] train loss: 0.841
[4,    50] train loss: 0.837
[4,    55] train loss: 0.835
[4,    60] train loss: 0.835
[4,    65] train loss: 0.847
[4,    70] train loss: 0.838
[4,    75] train loss: 0.835
[4,    80] train loss: 0.836
[4,    85] train loss: 0.833
[4,    90] train loss: 0.835
[4,    95] train loss: 0.834
[4,   100] train loss: 0.833
[4,   105] train loss: 0.842
[4,   110] train loss: 0.828
[4,   115] train loss: 0.838
[4,   120] train loss: 0.827
[4,   125] train loss: 0.827
[4,   130] train loss: 0.841
[4,   135] train loss: 0.850
[4,   140] train loss: 0.848
[4,   145] train loss: 0.841
[4,   150] train loss: 0.840
[4,   155] train loss: 0.845
[4,   160] train loss: 0.829
[4,   165] train loss: 0.839
[4,   170] train loss: 0.832
[4,   175] train loss: 0.831
[4,   180] train loss: 0.834
[4,   185] train loss: 0.825
[4,   190] train loss: 0.827
[4,   195] train loss: 0.820
[4,   200] train loss: 0.836
[4,   205] train loss: 0.822
[4,   210] train loss: 0.826
[4,   215] train loss: 0.826
[4,   220] train loss: 0.827
[4,   225] train loss: 0.830
[4,   230] train loss: 0.836
[4,   235] train loss: 0.831
[4,   240] train loss: 0.836
[4,   245] train loss: 0.831
[4,   250] train loss: 0.821
[4,   255] train loss: 0.843
[4,   260] train loss: 0.822
[4,   265] train loss: 0.825
[4,   270] train loss: 0.832
[4,   275] train loss: 0.819
[4,   280] train loss: 0.829
[4,   285] train loss: 0.837
[4,   290] train loss: 0.825
[4,   295] train loss: 0.833
[4,   300] train loss: 0.843
[4,   305] train loss: 0.833
[4,   310] train loss: 0.828
[4,   315] train loss: 0.848
[4,   320] train loss: 0.835
[4,   325] train loss: 0.826
[4,   330] train loss: 0.816
[4,   335] train loss: 0.821
[4,   340] train loss: 0.834
[4,   345] train loss: 0.831
[4,   350] train loss: 0.848
[4,   355] train loss: 0.826
[4,   360] train loss: 0.822
[4,   365] train loss: 0.835
[4,   370] train loss: 0.825
[4,   375] train loss: 0.808
[4,   380] train loss: 0.813
[4,   385] train loss: 0.839
[4,   390] train loss: 0.832
[4,   395] train loss: 0.831
[4,   400] train loss: 0.826
[4,   405] train loss: 0.816
[4,   410] train loss: 0.816
[4,   415] train loss: 0.824
[4,   420] train loss: 0.818
[4,   425] train loss: 0.816
[4,   430] train loss: 0.820
[4,   435] train loss: 0.812
[4,   440] train loss: 0.821
[4,   445] train loss: 0.832
[4,   450] train loss: 0.824
[4,   455] train loss: 0.818
[4,   460] train loss: 0.808
[4,   465] train loss: 0.813
[4,   470] train loss: 0.825
[4,   475] train loss: 0.819
[4,   480] train loss: 0.831
[4,   485] train loss: 0.808
[4,   490] train loss: 0.817
[4,   495] train loss: 0.823
[4,   500] train loss: 0.826
[4,   505] train loss: 0.832
[4,   510] train loss: 0.826
[4,   515] train loss: 0.810
[4,   520] train loss: 0.825
[4,   525] train loss: 0.832
[4,   530] train loss: 0.811
[4,   535] train loss: 0.816
[4,   540] train loss: 0.818
[4,   545] train loss: 0.837
[4,   550] train loss: 0.804
[4,   555] train loss: 0.815
[4,   560] train loss: 0.811
[4,   565] train loss: 0.843
[4,   570] train loss: 0.822
[4,   575] train loss: 0.816
[4,   580] train loss: 0.801
[4,   585] train loss: 0.814
[4,   590] train loss: 0.803
[4,   595] train loss: 0.839
[4,   600] train loss: 0.831
[4,   605] train loss: 0.808
[4,   610] train loss: 0.832
[4,   615] train loss: 0.825
[4,   620] train loss: 0.824
[4,   625] train loss: 0.833
[4,   630] train loss: 0.824
[4,   635] train loss: 0.827
[4,   640] train loss: 0.819
[4,   645] train loss: 0.814
[4,   650] train loss: 0.812
[4,   655] train loss: 0.826
Finished Training
[4,     5] test loss: 0.791
[4,    10] test loss: 0.819
[4,    15] test loss: 0.822
[4,    20] test loss: 0.808
[4,    25] test loss: 0.806
[4,    30] test loss: 0.821
[4,    35] test loss: 0.807
[4,    40] test loss: 0.790
[4,    45] test loss: 0.780
[4,    50] test loss: 0.804
[4,    55] test loss: 0.788
[4,    60] test loss: 0.791
[4,    65] test loss: 0.796
[4,    70] test loss: 0.805
[4,    75] test loss: 0.801
[4,    80] test loss: 0.808
[4,    85] test loss: 0.794
[4,    90] test loss: 0.781
[4,    95] test loss: 0.802
[4,   100] test loss: 0.798
[4,   105] test loss: 0.805
[4,   110] test loss: 0.798
[4,   115] test loss: 0.799
[4,   120] test loss: 0.793
[4,   125] test loss: 0.811
[4,   130] test loss: 0.810
[4,   135] test loss: 0.808
[4,   140] test loss: 0.806
[4,   145] test loss: 0.815
[4,   150] test loss: 0.794
[4,   155] test loss: 0.813
[4,   160] test loss: 0.795
[4,   165] test loss: 0.798
[4,   170] test loss: 0.800
[4,   175] test loss: 0.789
[4,   180] test loss: 0.781
[4,   185] test loss: 0.809
[4,   190] test loss: 0.808
[4,   195] test loss: 0.778
[4,   200] test loss: 0.777
[4,   205] test loss: 0.794
[4,   210] test loss: 0.802
[4,   215] test loss: 0.801
[4,   220] test loss: 0.816
-----------------------------------------------------------------------------------------
Micro-Precision: 0.15067078173160553, Macro-Precision: nan

Micro-Recall: 0.17075419425964355, Macro-Recall: nan

Micro-F1: 0.1600850522518158, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 159.86s | valid loss  0.80 | valid ppl     2.23
-----------------------------------------------------------------------------------------
[5,     5] train loss: 0.799
[5,    10] train loss: 0.805
[5,    15] train loss: 0.814
[5,    20] train loss: 0.827
[5,    25] train loss: 0.815
[5,    30] train loss: 0.806
[5,    35] train loss: 0.794
[5,    40] train loss: 0.827
[5,    45] train loss: 0.808
[5,    50] train loss: 0.801
[5,    55] train loss: 0.817
[5,    60] train loss: 0.798
[5,    65] train loss: 0.829
[5,    70] train loss: 0.829
[5,    75] train loss: 0.802
[5,    80] train loss: 0.814
[5,    85] train loss: 0.787
[5,    90] train loss: 0.802
[5,    95] train loss: 0.816
[5,   100] train loss: 0.805
[5,   105] train loss: 0.803
[5,   110] train loss: 0.806
[5,   115] train loss: 0.808
[5,   120] train loss: 0.804
[5,   125] train loss: 0.816
[5,   130] train loss: 0.813
[5,   135] train loss: 0.825
[5,   140] train loss: 0.829
[5,   145] train loss: 0.783
[5,   150] train loss: 0.802
[5,   155] train loss: 0.819
[5,   160] train loss: 0.811
[5,   165] train loss: 0.807
[5,   170] train loss: 0.844
[5,   175] train loss: 0.801
[5,   180] train loss: 0.808
[5,   185] train loss: 0.815
[5,   190] train loss: 0.808
[5,   195] train loss: 0.793
[5,   200] train loss: 0.809
[5,   205] train loss: 0.805
[5,   210] train loss: 0.811
[5,   215] train loss: 0.807
[5,   220] train loss: 0.807
[5,   225] train loss: 0.814
[5,   230] train loss: 0.800
[5,   235] train loss: 0.802
[5,   240] train loss: 0.821
[5,   245] train loss: 0.807
[5,   250] train loss: 0.811
[5,   255] train loss: 0.827
[5,   260] train loss: 0.810
[5,   265] train loss: 0.827
[5,   270] train loss: 0.807
[5,   275] train loss: 0.801
[5,   280] train loss: 0.828
[5,   285] train loss: 0.803
[5,   290] train loss: 0.803
[5,   295] train loss: 0.836
[5,   300] train loss: 0.807
[5,   305] train loss: 0.818
[5,   310] train loss: 0.810
[5,   315] train loss: 0.819
[5,   320] train loss: 0.810
[5,   325] train loss: 0.781
[5,   330] train loss: 0.813
[5,   335] train loss: 0.812
[5,   340] train loss: 0.806
[5,   345] train loss: 0.824
[5,   350] train loss: 0.802
[5,   355] train loss: 0.803
[5,   360] train loss: 0.809
[5,   365] train loss: 0.801
[5,   370] train loss: 0.822
[5,   375] train loss: 0.817
[5,   380] train loss: 0.796
[5,   385] train loss: 0.800
[5,   390] train loss: 0.804
[5,   395] train loss: 0.810
[5,   400] train loss: 0.819
[5,   405] train loss: 0.817
[5,   410] train loss: 0.816
[5,   415] train loss: 0.814
[5,   420] train loss: 0.809
[5,   425] train loss: 0.816
[5,   430] train loss: 0.810
[5,   435] train loss: 0.806
[5,   440] train loss: 0.795
[5,   445] train loss: 0.810
[5,   450] train loss: 0.833
[5,   455] train loss: 0.825
[5,   460] train loss: 0.816
[5,   465] train loss: 0.803
[5,   470] train loss: 0.799
[5,   475] train loss: 0.806
[5,   480] train loss: 0.803
[5,   485] train loss: 0.813
[5,   490] train loss: 0.785
[5,   495] train loss: 0.805
[5,   500] train loss: 0.835
[5,   505] train loss: 0.817
[5,   510] train loss: 0.823
[5,   515] train loss: 0.790
[5,   520] train loss: 0.797
[5,   525] train loss: 0.778
[5,   530] train loss: 0.815
[5,   535] train loss: 0.813
[5,   540] train loss: 0.807
[5,   545] train loss: 0.802
[5,   550] train loss: 0.798
[5,   555] train loss: 0.813
[5,   560] train loss: 0.819
[5,   565] train loss: 0.828
[5,   570] train loss: 0.807
[5,   575] train loss: 0.823
[5,   580] train loss: 0.818
[5,   585] train loss: 0.802
[5,   590] train loss: 0.803
[5,   595] train loss: 0.799
[5,   600] train loss: 0.798
[5,   605] train loss: 0.802
[5,   610] train loss: 0.805
[5,   615] train loss: 0.800
[5,   620] train loss: 0.794
[5,   625] train loss: 0.803
[5,   630] train loss: 0.822
[5,   635] train loss: 0.769
[5,   640] train loss: 0.786
[5,   645] train loss: 0.787
[5,   650] train loss: 0.799
[5,   655] train loss: 0.797
Finished Training
[5,     5] test loss: 0.776
[5,    10] test loss: 0.780
[5,    15] test loss: 0.813
[5,    20] test loss: 0.799
[5,    25] test loss: 0.768
[5,    30] test loss: 0.760
[5,    35] test loss: 0.796
[5,    40] test loss: 0.774
[5,    45] test loss: 0.778
[5,    50] test loss: 0.770
[5,    55] test loss: 0.816
[5,    60] test loss: 0.770
[5,    65] test loss: 0.767
[5,    70] test loss: 0.794
[5,    75] test loss: 0.805
[5,    80] test loss: 0.763
[5,    85] test loss: 0.787
[5,    90] test loss: 0.786
[5,    95] test loss: 0.772
[5,   100] test loss: 0.764
[5,   105] test loss: 0.780
[5,   110] test loss: 0.796
[5,   115] test loss: 0.780
[5,   120] test loss: 0.793
[5,   125] test loss: 0.797
[5,   130] test loss: 0.762
[5,   135] test loss: 0.809
[5,   140] test loss: 0.784
[5,   145] test loss: 0.793
[5,   150] test loss: 0.780
[5,   155] test loss: 0.772
[5,   160] test loss: 0.785
[5,   165] test loss: 0.777
[5,   170] test loss: 0.775
[5,   175] test loss: 0.790
[5,   180] test loss: 0.803
[5,   185] test loss: 0.787
[5,   190] test loss: 0.777
[5,   195] test loss: 0.771
[5,   200] test loss: 0.805
[5,   205] test loss: 0.786
[5,   210] test loss: 0.760
[5,   215] test loss: 0.797
[5,   220] test loss: 0.765
-----------------------------------------------------------------------------------------
Micro-Precision: 0.18038922548294067, Macro-Precision: nan

Micro-Recall: 0.1974889487028122, Macro-Recall: nan

Micro-F1: 0.18855218589305878, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 159.28s | valid loss  0.79 | valid ppl     2.20
-----------------------------------------------------------------------------------------
[6,     5] train loss: 0.794
[6,    10] train loss: 0.796
[6,    15] train loss: 0.800
[6,    20] train loss: 0.812
[6,    25] train loss: 0.784
[6,    30] train loss: 0.810
[6,    35] train loss: 0.806
[6,    40] train loss: 0.801
[6,    45] train loss: 0.794
[6,    50] train loss: 0.785
[6,    55] train loss: 0.804
[6,    60] train loss: 0.803
[6,    65] train loss: 0.773
[6,    70] train loss: 0.801
[6,    75] train loss: 0.800
[6,    80] train loss: 0.810
[6,    85] train loss: 0.804
[6,    90] train loss: 0.786
[6,    95] train loss: 0.783
[6,   100] train loss: 0.807
[6,   105] train loss: 0.801
[6,   110] train loss: 0.786
[6,   115] train loss: 0.801
[6,   120] train loss: 0.803
[6,   125] train loss: 0.777
[6,   130] train loss: 0.805
[6,   135] train loss: 0.808
[6,   140] train loss: 0.799
[6,   145] train loss: 0.799
[6,   150] train loss: 0.793
[6,   155] train loss: 0.776
[6,   160] train loss: 0.804
[6,   165] train loss: 0.807
[6,   170] train loss: 0.792
[6,   175] train loss: 0.809
[6,   180] train loss: 0.795
[6,   185] train loss: 0.784
[6,   190] train loss: 0.806
[6,   195] train loss: 0.794
[6,   200] train loss: 0.798
[6,   205] train loss: 0.793
[6,   210] train loss: 0.807
[6,   215] train loss: 0.794
[6,   220] train loss: 0.790
[6,   225] train loss: 0.784
[6,   230] train loss: 0.784
[6,   235] train loss: 0.778
[6,   240] train loss: 0.812
[6,   245] train loss: 0.790
[6,   250] train loss: 0.785
[6,   255] train loss: 0.794
[6,   260] train loss: 0.802
[6,   265] train loss: 0.803
[6,   270] train loss: 0.792
[6,   275] train loss: 0.796
[6,   280] train loss: 0.776
[6,   285] train loss: 0.809
[6,   290] train loss: 0.786
[6,   295] train loss: 0.800
[6,   300] train loss: 0.791
[6,   305] train loss: 0.788
[6,   310] train loss: 0.784
[6,   315] train loss: 0.793
[6,   320] train loss: 0.805
[6,   325] train loss: 0.780
[6,   330] train loss: 0.792
[6,   335] train loss: 0.796
[6,   340] train loss: 0.791
[6,   345] train loss: 0.784
[6,   350] train loss: 0.794
[6,   355] train loss: 0.790
[6,   360] train loss: 0.793
[6,   365] train loss: 0.794
[6,   370] train loss: 0.808
[6,   375] train loss: 0.779
[6,   380] train loss: 0.781
[6,   385] train loss: 0.814
[6,   390] train loss: 0.781
[6,   395] train loss: 0.794
[6,   400] train loss: 0.796
[6,   405] train loss: 0.766
[6,   410] train loss: 0.778
[6,   415] train loss: 0.795
[6,   420] train loss: 0.766
[6,   425] train loss: 0.801
[6,   430] train loss: 0.786
[6,   435] train loss: 0.786
[6,   440] train loss: 0.792
[6,   445] train loss: 0.788
[6,   450] train loss: 0.788
[6,   455] train loss: 0.794
[6,   460] train loss: 0.798
[6,   465] train loss: 0.788
[6,   470] train loss: 0.793
[6,   475] train loss: 0.787
[6,   480] train loss: 0.783
[6,   485] train loss: 0.786
[6,   490] train loss: 0.782
[6,   495] train loss: 0.794
[6,   500] train loss: 0.821
[6,   505] train loss: 0.794
[6,   510] train loss: 0.787
[6,   515] train loss: 0.778
[6,   520] train loss: 0.783
[6,   525] train loss: 0.786
[6,   530] train loss: 0.799
[6,   535] train loss: 0.769
[6,   540] train loss: 0.793
[6,   545] train loss: 0.814
[6,   550] train loss: 0.789
[6,   555] train loss: 0.786
[6,   560] train loss: 0.789
[6,   565] train loss: 0.775
[6,   570] train loss: 0.766
[6,   575] train loss: 0.790
[6,   580] train loss: 0.788
[6,   585] train loss: 0.768
[6,   590] train loss: 0.783
[6,   595] train loss: 0.779
[6,   600] train loss: 0.820
[6,   605] train loss: 0.798
[6,   610] train loss: 0.796
[6,   615] train loss: 0.822
[6,   620] train loss: 0.785
[6,   625] train loss: 0.792
[6,   630] train loss: 0.813
[6,   635] train loss: 0.770
[6,   640] train loss: 0.784
[6,   645] train loss: 0.781
[6,   650] train loss: 0.791
[6,   655] train loss: 0.794
Finished Training
[6,     5] test loss: 0.791
[6,    10] test loss: 0.762
[6,    15] test loss: 0.774
[6,    20] test loss: 0.760
[6,    25] test loss: 0.768
[6,    30] test loss: 0.771
[6,    35] test loss: 0.751
[6,    40] test loss: 0.783
[6,    45] test loss: 0.786
[6,    50] test loss: 0.765
[6,    55] test loss: 0.762
[6,    60] test loss: 0.751
[6,    65] test loss: 0.777
[6,    70] test loss: 0.726
[6,    75] test loss: 0.770
[6,    80] test loss: 0.750
[6,    85] test loss: 0.778
[6,    90] test loss: 0.777
[6,    95] test loss: 0.747
[6,   100] test loss: 0.746
[6,   105] test loss: 0.754
[6,   110] test loss: 0.783
[6,   115] test loss: 0.761
[6,   120] test loss: 0.777
[6,   125] test loss: 0.804
[6,   130] test loss: 0.771
[6,   135] test loss: 0.751
[6,   140] test loss: 0.758
[6,   145] test loss: 0.759
[6,   150] test loss: 0.767
[6,   155] test loss: 0.794
[6,   160] test loss: 0.770
[6,   165] test loss: 0.772
[6,   170] test loss: 0.769
[6,   175] test loss: 0.784
[6,   180] test loss: 0.754
[6,   185] test loss: 0.767
[6,   190] test loss: 0.795
[6,   195] test loss: 0.776
[6,   200] test loss: 0.749
[6,   205] test loss: 0.771
[6,   210] test loss: 0.772
[6,   215] test loss: 0.764
[6,   220] test loss: 0.771
-----------------------------------------------------------------------------------------
Micro-Precision: 0.20177440345287323, Macro-Precision: nan

Micro-Recall: 0.2096637338399887, Macro-Recall: nan

Micro-F1: 0.205643430352211, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 158.60s | valid loss  0.77 | valid ppl     2.16
-----------------------------------------------------------------------------------------
[7,     5] train loss: 0.784
[7,    10] train loss: 0.767
[7,    15] train loss: 0.766
[7,    20] train loss: 0.774
[7,    25] train loss: 0.776
[7,    30] train loss: 0.790
[7,    35] train loss: 0.777
[7,    40] train loss: 0.787
[7,    45] train loss: 0.781
[7,    50] train loss: 0.796
[7,    55] train loss: 0.799
[7,    60] train loss: 0.805
[7,    65] train loss: 0.777
[7,    70] train loss: 0.778
[7,    75] train loss: 0.777
[7,    80] train loss: 0.786
[7,    85] train loss: 0.804
[7,    90] train loss: 0.774
[7,    95] train loss: 0.781
[7,   100] train loss: 0.794
[7,   105] train loss: 0.794
[7,   110] train loss: 0.783
[7,   115] train loss: 0.775
[7,   120] train loss: 0.772
[7,   125] train loss: 0.789
[7,   130] train loss: 0.800
[7,   135] train loss: 0.786
[7,   140] train loss: 0.793
[7,   145] train loss: 0.802
[7,   150] train loss: 0.784
[7,   155] train loss: 0.793
[7,   160] train loss: 0.792
[7,   165] train loss: 0.793
[7,   170] train loss: 0.777
[7,   175] train loss: 0.757
[7,   180] train loss: 0.783
[7,   185] train loss: 0.780
[7,   190] train loss: 0.770
[7,   195] train loss: 0.773
[7,   200] train loss: 0.779
[7,   205] train loss: 0.768
[7,   210] train loss: 0.784
[7,   215] train loss: 0.787
[7,   220] train loss: 0.778
[7,   225] train loss: 0.782
[7,   230] train loss: 0.799
[7,   235] train loss: 0.771
[7,   240] train loss: 0.792
[7,   245] train loss: 0.756
[7,   250] train loss: 0.780
[7,   255] train loss: 0.782
[7,   260] train loss: 0.776
[7,   265] train loss: 0.785
[7,   270] train loss: 0.795
[7,   275] train loss: 0.756
[7,   280] train loss: 0.771
[7,   285] train loss: 0.782
[7,   290] train loss: 0.787
[7,   295] train loss: 0.768
[7,   300] train loss: 0.775
[7,   305] train loss: 0.766
[7,   310] train loss: 0.795
[7,   315] train loss: 0.760
[7,   320] train loss: 0.792
[7,   325] train loss: 0.779
[7,   330] train loss: 0.782
[7,   335] train loss: 0.799
[7,   340] train loss: 0.777
[7,   345] train loss: 0.773
[7,   350] train loss: 0.806
[7,   355] train loss: 0.781
[7,   360] train loss: 0.786
[7,   365] train loss: 0.763
[7,   370] train loss: 0.804
[7,   375] train loss: 0.788
[7,   380] train loss: 0.793
[7,   385] train loss: 0.786
[7,   390] train loss: 0.774
[7,   395] train loss: 0.777
[7,   400] train loss: 0.767
[7,   405] train loss: 0.782
[7,   410] train loss: 0.751
[7,   415] train loss: 0.776
[7,   420] train loss: 0.766
[7,   425] train loss: 0.775
[7,   430] train loss: 0.780
[7,   435] train loss: 0.762
[7,   440] train loss: 0.778
[7,   445] train loss: 0.780
[7,   450] train loss: 0.780
[7,   455] train loss: 0.769
[7,   460] train loss: 0.776
[7,   465] train loss: 0.767
[7,   470] train loss: 0.771
[7,   475] train loss: 0.785
[7,   480] train loss: 0.778
[7,   485] train loss: 0.752
[7,   490] train loss: 0.775
[7,   495] train loss: 0.765
[7,   500] train loss: 0.775
[7,   505] train loss: 0.799
[7,   510] train loss: 0.763
[7,   515] train loss: 0.788
[7,   520] train loss: 0.770
[7,   525] train loss: 0.790
[7,   530] train loss: 0.762
[7,   535] train loss: 0.782
[7,   540] train loss: 0.771
[7,   545] train loss: 0.766
[7,   550] train loss: 0.772
[7,   555] train loss: 0.786
[7,   560] train loss: 0.759
[7,   565] train loss: 0.792
[7,   570] train loss: 0.786
[7,   575] train loss: 0.774
[7,   580] train loss: 0.780
[7,   585] train loss: 0.763
[7,   590] train loss: 0.763
[7,   595] train loss: 0.770
[7,   600] train loss: 0.775
[7,   605] train loss: 0.775
[7,   610] train loss: 0.770
[7,   615] train loss: 0.792
[7,   620] train loss: 0.795
[7,   625] train loss: 0.784
[7,   630] train loss: 0.771
[7,   635] train loss: 0.788
[7,   640] train loss: 0.746
[7,   645] train loss: 0.786
[7,   650] train loss: 0.768
[7,   655] train loss: 0.768
Finished Training
[7,     5] test loss: 0.773
[7,    10] test loss: 0.736
[7,    15] test loss: 0.776
[7,    20] test loss: 0.756
[7,    25] test loss: 0.762
[7,    30] test loss: 0.766
[7,    35] test loss: 0.754
[7,    40] test loss: 0.765
[7,    45] test loss: 0.764
[7,    50] test loss: 0.751
[7,    55] test loss: 0.766
[7,    60] test loss: 0.762
[7,    65] test loss: 0.734
[7,    70] test loss: 0.774
[7,    75] test loss: 0.763
[7,    80] test loss: 0.732
[7,    85] test loss: 0.756
[7,    90] test loss: 0.774
[7,    95] test loss: 0.745
[7,   100] test loss: 0.774
[7,   105] test loss: 0.733
[7,   110] test loss: 0.723
[7,   115] test loss: 0.739
[7,   120] test loss: 0.757
[7,   125] test loss: 0.759
[7,   130] test loss: 0.752
[7,   135] test loss: 0.760
[7,   140] test loss: 0.747
[7,   145] test loss: 0.774
[7,   150] test loss: 0.768
[7,   155] test loss: 0.760
[7,   160] test loss: 0.771
[7,   165] test loss: 0.768
[7,   170] test loss: 0.783
[7,   175] test loss: 0.769
[7,   180] test loss: 0.754
[7,   185] test loss: 0.744
[7,   190] test loss: 0.755
[7,   195] test loss: 0.773
[7,   200] test loss: 0.743
[7,   205] test loss: 0.720
[7,   210] test loss: 0.735
[7,   215] test loss: 0.732
[7,   220] test loss: 0.742
-----------------------------------------------------------------------------------------
Micro-Precision: 0.21632647514343262, Macro-Precision: nan

Micro-Recall: 0.2358863353729248, Macro-Recall: nan

Micro-F1: 0.22568339109420776, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 159.45s | valid loss  0.76 | valid ppl     2.14
-----------------------------------------------------------------------------------------
[8,     5] train loss: 0.760
[8,    10] train loss: 0.772
[8,    15] train loss: 0.782
[8,    20] train loss: 0.759
[8,    25] train loss: 0.770
[8,    30] train loss: 0.775
[8,    35] train loss: 0.748
[8,    40] train loss: 0.764
[8,    45] train loss: 0.765
[8,    50] train loss: 0.781
[8,    55] train loss: 0.785
[8,    60] train loss: 0.780
[8,    65] train loss: 0.769
[8,    70] train loss: 0.778
[8,    75] train loss: 0.777
[8,    80] train loss: 0.755
[8,    85] train loss: 0.778
[8,    90] train loss: 0.783
[8,    95] train loss: 0.777
[8,   100] train loss: 0.769
[8,   105] train loss: 0.787
[8,   110] train loss: 0.784
[8,   115] train loss: 0.793
[8,   120] train loss: 0.772
[8,   125] train loss: 0.779
[8,   130] train loss: 0.765
[8,   135] train loss: 0.772
[8,   140] train loss: 0.771
[8,   145] train loss: 0.774
[8,   150] train loss: 0.766
[8,   155] train loss: 0.755
[8,   160] train loss: 0.770
[8,   165] train loss: 0.769
[8,   170] train loss: 0.777
[8,   175] train loss: 0.768
[8,   180] train loss: 0.747
[8,   185] train loss: 0.758
[8,   190] train loss: 0.749
[8,   195] train loss: 0.775
[8,   200] train loss: 0.799
[8,   205] train loss: 0.783
[8,   210] train loss: 0.759
[8,   215] train loss: 0.757
[8,   220] train loss: 0.776
[8,   225] train loss: 0.764
[8,   230] train loss: 0.746
[8,   235] train loss: 0.769
[8,   240] train loss: 0.769
[8,   245] train loss: 0.753
[8,   250] train loss: 0.773
[8,   255] train loss: 0.768
[8,   260] train loss: 0.761
[8,   265] train loss: 0.761
[8,   270] train loss: 0.759
[8,   275] train loss: 0.786
[8,   280] train loss: 0.781
[8,   285] train loss: 0.753
[8,   290] train loss: 0.782
[8,   295] train loss: 0.769
[8,   300] train loss: 0.756
[8,   305] train loss: 0.761
[8,   310] train loss: 0.774
[8,   315] train loss: 0.759
[8,   320] train loss: 0.769
[8,   325] train loss: 0.779
[8,   330] train loss: 0.753
[8,   335] train loss: 0.769
[8,   340] train loss: 0.781
[8,   345] train loss: 0.753
[8,   350] train loss: 0.785
[8,   355] train loss: 0.779
[8,   360] train loss: 0.758
[8,   365] train loss: 0.772
[8,   370] train loss: 0.767
[8,   375] train loss: 0.756
[8,   380] train loss: 0.772
[8,   385] train loss: 0.761
[8,   390] train loss: 0.760
[8,   395] train loss: 0.746
[8,   400] train loss: 0.762
[8,   405] train loss: 0.761
[8,   410] train loss: 0.766
[8,   415] train loss: 0.764
[8,   420] train loss: 0.778
[8,   425] train loss: 0.748
[8,   430] train loss: 0.749
[8,   435] train loss: 0.765
[8,   440] train loss: 0.776
[8,   445] train loss: 0.776
[8,   450] train loss: 0.770
[8,   455] train loss: 0.750
[8,   460] train loss: 0.765
[8,   465] train loss: 0.753
[8,   470] train loss: 0.778
[8,   475] train loss: 0.767
[8,   480] train loss: 0.777
[8,   485] train loss: 0.771
[8,   490] train loss: 0.760
[8,   495] train loss: 0.761
[8,   500] train loss: 0.775
[8,   505] train loss: 0.765
[8,   510] train loss: 0.766
[8,   515] train loss: 0.738
[8,   520] train loss: 0.745
[8,   525] train loss: 0.765
[8,   530] train loss: 0.780
[8,   535] train loss: 0.790
[8,   540] train loss: 0.755
[8,   545] train loss: 0.758
[8,   550] train loss: 0.749
[8,   555] train loss: 0.775
[8,   560] train loss: 0.764
[8,   565] train loss: 0.785
[8,   570] train loss: 0.766
[8,   575] train loss: 0.773
[8,   580] train loss: 0.758
[8,   585] train loss: 0.760
[8,   590] train loss: 0.783
[8,   595] train loss: 0.758
[8,   600] train loss: 0.749
[8,   605] train loss: 0.761
[8,   610] train loss: 0.773
[8,   615] train loss: 0.780
[8,   620] train loss: 0.772
[8,   625] train loss: 0.764
[8,   630] train loss: 0.741
[8,   635] train loss: 0.769
[8,   640] train loss: 0.762
[8,   645] train loss: 0.774
[8,   650] train loss: 0.753
[8,   655] train loss: 0.764
Finished Training
[8,     5] test loss: 0.744
[8,    10] test loss: 0.751
[8,    15] test loss: 0.763
[8,    20] test loss: 0.768
[8,    25] test loss: 0.736
[8,    30] test loss: 0.739
[8,    35] test loss: 0.743
[8,    40] test loss: 0.755
[8,    45] test loss: 0.731
[8,    50] test loss: 0.763
[8,    55] test loss: 0.729
[8,    60] test loss: 0.699
[8,    65] test loss: 0.778
[8,    70] test loss: 0.757
[8,    75] test loss: 0.757
[8,    80] test loss: 0.768
[8,    85] test loss: 0.720
[8,    90] test loss: 0.753
[8,    95] test loss: 0.745
[8,   100] test loss: 0.751
[8,   105] test loss: 0.742
[8,   110] test loss: 0.749
[8,   115] test loss: 0.738
[8,   120] test loss: 0.773
[8,   125] test loss: 0.734
[8,   130] test loss: 0.750
[8,   135] test loss: 0.733
[8,   140] test loss: 0.736
[8,   145] test loss: 0.758
[8,   150] test loss: 0.717
[8,   155] test loss: 0.732
[8,   160] test loss: 0.748
[8,   165] test loss: 0.761
[8,   170] test loss: 0.750
[8,   175] test loss: 0.752
[8,   180] test loss: 0.741
[8,   185] test loss: 0.752
[8,   190] test loss: 0.762
[8,   195] test loss: 0.747
[8,   200] test loss: 0.729
[8,   205] test loss: 0.723
[8,   210] test loss: 0.704
[8,   215] test loss: 0.736
[8,   220] test loss: 0.731
-----------------------------------------------------------------------------------------
Micro-Precision: 0.22696223855018616, Macro-Precision: nan

Micro-Recall: 0.23579591512680054, Macro-Recall: nan

Micro-F1: 0.23129476606845856, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 158.46s | valid loss  0.75 | valid ppl     2.11
-----------------------------------------------------------------------------------------
[9,     5] train loss: 0.776
[9,    10] train loss: 0.771
[9,    15] train loss: 0.757
[9,    20] train loss: 0.765
[9,    25] train loss: 0.755
[9,    30] train loss: 0.763
[9,    35] train loss: 0.768
[9,    40] train loss: 0.766
[9,    45] train loss: 0.776
[9,    50] train loss: 0.748
[9,    55] train loss: 0.744
[9,    60] train loss: 0.745
[9,    65] train loss: 0.737
[9,    70] train loss: 0.762
[9,    75] train loss: 0.737
[9,    80] train loss: 0.758
[9,    85] train loss: 0.770
[9,    90] train loss: 0.755
[9,    95] train loss: 0.745
[9,   100] train loss: 0.765
[9,   105] train loss: 0.746
[9,   110] train loss: 0.752
[9,   115] train loss: 0.780
[9,   120] train loss: 0.747
[9,   125] train loss: 0.756
[9,   130] train loss: 0.759
[9,   135] train loss: 0.766
[9,   140] train loss: 0.745
[9,   145] train loss: 0.770
[9,   150] train loss: 0.743
[9,   155] train loss: 0.777
[9,   160] train loss: 0.747
[9,   165] train loss: 0.744
[9,   170] train loss: 0.752
[9,   175] train loss: 0.772
[9,   180] train loss: 0.757
[9,   185] train loss: 0.757
[9,   190] train loss: 0.759
[9,   195] train loss: 0.767
[9,   200] train loss: 0.775
[9,   205] train loss: 0.751
[9,   210] train loss: 0.747
[9,   215] train loss: 0.762
[9,   220] train loss: 0.774
[9,   225] train loss: 0.757
[9,   230] train loss: 0.758
[9,   235] train loss: 0.771
[9,   240] train loss: 0.754
[9,   245] train loss: 0.738
[9,   250] train loss: 0.728
[9,   255] train loss: 0.752
[9,   260] train loss: 0.758
[9,   265] train loss: 0.749
[9,   270] train loss: 0.744
[9,   275] train loss: 0.754
[9,   280] train loss: 0.769
[9,   285] train loss: 0.739
[9,   290] train loss: 0.791
[9,   295] train loss: 0.776
[9,   300] train loss: 0.753
[9,   305] train loss: 0.745
[9,   310] train loss: 0.761
[9,   315] train loss: 0.746
[9,   320] train loss: 0.776
[9,   325] train loss: 0.736
[9,   330] train loss: 0.744
[9,   335] train loss: 0.759
[9,   340] train loss: 0.761
[9,   345] train loss: 0.762
[9,   350] train loss: 0.759
[9,   355] train loss: 0.772
[9,   360] train loss: 0.750
[9,   365] train loss: 0.752
[9,   370] train loss: 0.762
[9,   375] train loss: 0.753
[9,   380] train loss: 0.758
[9,   385] train loss: 0.744
[9,   390] train loss: 0.747
[9,   395] train loss: 0.752
[9,   400] train loss: 0.755
[9,   405] train loss: 0.751
[9,   410] train loss: 0.742
[9,   415] train loss: 0.757
[9,   420] train loss: 0.764
[9,   425] train loss: 0.752
[9,   430] train loss: 0.770
[9,   435] train loss: 0.750
[9,   440] train loss: 0.741
[9,   445] train loss: 0.777
[9,   450] train loss: 0.758
[9,   455] train loss: 0.753
[9,   460] train loss: 0.758
[9,   465] train loss: 0.760
[9,   470] train loss: 0.755
[9,   475] train loss: 0.767
[9,   480] train loss: 0.777
[9,   485] train loss: 0.740
[9,   490] train loss: 0.747
[9,   495] train loss: 0.777
[9,   500] train loss: 0.756
[9,   505] train loss: 0.762
[9,   510] train loss: 0.754
[9,   515] train loss: 0.745
[9,   520] train loss: 0.746
[9,   525] train loss: 0.750
[9,   530] train loss: 0.755
[9,   535] train loss: 0.761
[9,   540] train loss: 0.740
[9,   545] train loss: 0.773
[9,   550] train loss: 0.751
[9,   555] train loss: 0.743
[9,   560] train loss: 0.746
[9,   565] train loss: 0.770
[9,   570] train loss: 0.766
[9,   575] train loss: 0.760
[9,   580] train loss: 0.771
[9,   585] train loss: 0.767
[9,   590] train loss: 0.760
[9,   595] train loss: 0.744
[9,   600] train loss: 0.752
[9,   605] train loss: 0.753
[9,   610] train loss: 0.748
[9,   615] train loss: 0.780
[9,   620] train loss: 0.759
[9,   625] train loss: 0.726
[9,   630] train loss: 0.766
[9,   635] train loss: 0.753
[9,   640] train loss: 0.752
[9,   645] train loss: 0.731
[9,   650] train loss: 0.764
[9,   655] train loss: 0.737
Finished Training
[9,     5] test loss: 0.721
[9,    10] test loss: 0.707
[9,    15] test loss: 0.733
[9,    20] test loss: 0.745
[9,    25] test loss: 0.697
[9,    30] test loss: 0.724
[9,    35] test loss: 0.729
[9,    40] test loss: 0.755
[9,    45] test loss: 0.722
[9,    50] test loss: 0.718
[9,    55] test loss: 0.752
[9,    60] test loss: 0.744
[9,    65] test loss: 0.735
[9,    70] test loss: 0.734
[9,    75] test loss: 0.742
[9,    80] test loss: 0.730
[9,    85] test loss: 0.738
[9,    90] test loss: 0.719
[9,    95] test loss: 0.754
[9,   100] test loss: 0.744
[9,   105] test loss: 0.714
[9,   110] test loss: 0.719
[9,   115] test loss: 0.744
[9,   120] test loss: 0.739
[9,   125] test loss: 0.745
[9,   130] test loss: 0.724
[9,   135] test loss: 0.750
[9,   140] test loss: 0.720
[9,   145] test loss: 0.742
[9,   150] test loss: 0.743
[9,   155] test loss: 0.735
[9,   160] test loss: 0.745
[9,   165] test loss: 0.737
[9,   170] test loss: 0.715
[9,   175] test loss: 0.733
[9,   180] test loss: 0.765
[9,   185] test loss: 0.710
[9,   190] test loss: 0.778
[9,   195] test loss: 0.750
[9,   200] test loss: 0.771
[9,   205] test loss: 0.709
[9,   210] test loss: 0.730
[9,   215] test loss: 0.735
[9,   220] test loss: 0.740
-----------------------------------------------------------------------------------------
Micro-Precision: 0.23940768837928772, Macro-Precision: nan

Micro-Recall: 0.2626064419746399, Macro-Recall: nan

Micro-F1: 0.2504710555076599, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 159.11s | valid loss  0.74 | valid ppl     2.09
-----------------------------------------------------------------------------------------
[10,     5] train loss: 0.746
[10,    10] train loss: 0.770
[10,    15] train loss: 0.743
[10,    20] train loss: 0.758
[10,    25] train loss: 0.732
[10,    30] train loss: 0.724
[10,    35] train loss: 0.762
[10,    40] train loss: 0.743
[10,    45] train loss: 0.745
[10,    50] train loss: 0.757
[10,    55] train loss: 0.760
[10,    60] train loss: 0.760
[10,    65] train loss: 0.750
[10,    70] train loss: 0.740
[10,    75] train loss: 0.744
[10,    80] train loss: 0.743
[10,    85] train loss: 0.732
[10,    90] train loss: 0.754
[10,    95] train loss: 0.744
[10,   100] train loss: 0.754
[10,   105] train loss: 0.751
[10,   110] train loss: 0.756
[10,   115] train loss: 0.755
[10,   120] train loss: 0.753
[10,   125] train loss: 0.720
[10,   130] train loss: 0.752
[10,   135] train loss: 0.756
[10,   140] train loss: 0.771
[10,   145] train loss: 0.740
[10,   150] train loss: 0.728
[10,   155] train loss: 0.747
[10,   160] train loss: 0.736
[10,   165] train loss: 0.733
[10,   170] train loss: 0.748
[10,   175] train loss: 0.743
[10,   180] train loss: 0.754
[10,   185] train loss: 0.769
[10,   190] train loss: 0.756
[10,   195] train loss: 0.791
[10,   200] train loss: 0.751
[10,   205] train loss: 0.745
[10,   210] train loss: 0.734
[10,   215] train loss: 0.741
[10,   220] train loss: 0.741
[10,   225] train loss: 0.747
[10,   230] train loss: 0.748
[10,   235] train loss: 0.735
[10,   240] train loss: 0.773
[10,   245] train loss: 0.738
[10,   250] train loss: 0.750
[10,   255] train loss: 0.744
[10,   260] train loss: 0.745
[10,   265] train loss: 0.762
[10,   270] train loss: 0.757
[10,   275] train loss: 0.747
[10,   280] train loss: 0.755
[10,   285] train loss: 0.745
[10,   290] train loss: 0.746
[10,   295] train loss: 0.747
[10,   300] train loss: 0.738
[10,   305] train loss: 0.738
[10,   310] train loss: 0.758
[10,   315] train loss: 0.748
[10,   320] train loss: 0.745
[10,   325] train loss: 0.739
[10,   330] train loss: 0.774
[10,   335] train loss: 0.739
[10,   340] train loss: 0.759
[10,   345] train loss: 0.760
[10,   350] train loss: 0.764
[10,   355] train loss: 0.741
[10,   360] train loss: 0.752
[10,   365] train loss: 0.741
[10,   370] train loss: 0.748
[10,   375] train loss: 0.748
[10,   380] train loss: 0.716
[10,   385] train loss: 0.753
[10,   390] train loss: 0.718
[10,   395] train loss: 0.735
[10,   400] train loss: 0.743
[10,   405] train loss: 0.738
[10,   410] train loss: 0.733
[10,   415] train loss: 0.725
[10,   420] train loss: 0.739
[10,   425] train loss: 0.747
[10,   430] train loss: 0.742
[10,   435] train loss: 0.755
[10,   440] train loss: 0.751
[10,   445] train loss: 0.767
[10,   450] train loss: 0.750
[10,   455] train loss: 0.723
[10,   460] train loss: 0.755
[10,   465] train loss: 0.729
[10,   470] train loss: 0.753
[10,   475] train loss: 0.741
[10,   480] train loss: 0.747
[10,   485] train loss: 0.740
[10,   490] train loss: 0.753
[10,   495] train loss: 0.741
[10,   500] train loss: 0.751
[10,   505] train loss: 0.743
[10,   510] train loss: 0.745
[10,   515] train loss: 0.732
[10,   520] train loss: 0.762
[10,   525] train loss: 0.769
[10,   530] train loss: 0.736
[10,   535] train loss: 0.757
[10,   540] train loss: 0.734
[10,   545] train loss: 0.744
[10,   550] train loss: 0.770
[10,   555] train loss: 0.749
[10,   560] train loss: 0.760
[10,   565] train loss: 0.743
[10,   570] train loss: 0.745
[10,   575] train loss: 0.717
[10,   580] train loss: 0.749
[10,   585] train loss: 0.755
[10,   590] train loss: 0.744
[10,   595] train loss: 0.747
[10,   600] train loss: 0.722
[10,   605] train loss: 0.723
[10,   610] train loss: 0.734
[10,   615] train loss: 0.759
[10,   620] train loss: 0.754
[10,   625] train loss: 0.754
[10,   630] train loss: 0.733
[10,   635] train loss: 0.748
[10,   640] train loss: 0.749
[10,   645] train loss: 0.745
[10,   650] train loss: 0.705
[10,   655] train loss: 0.743
Finished Training
[10,     5] test loss: 0.739
[10,    10] test loss: 0.729
[10,    15] test loss: 0.706
[10,    20] test loss: 0.763
[10,    25] test loss: 0.719
[10,    30] test loss: 0.720
[10,    35] test loss: 0.696
[10,    40] test loss: 0.750
[10,    45] test loss: 0.745
[10,    50] test loss: 0.686
[10,    55] test loss: 0.743
[10,    60] test loss: 0.747
[10,    65] test loss: 0.729
[10,    70] test loss: 0.766
[10,    75] test loss: 0.743
[10,    80] test loss: 0.733
[10,    85] test loss: 0.719
[10,    90] test loss: 0.710
[10,    95] test loss: 0.755
[10,   100] test loss: 0.720
[10,   105] test loss: 0.711
[10,   110] test loss: 0.732
[10,   115] test loss: 0.720
[10,   120] test loss: 0.726
[10,   125] test loss: 0.699
[10,   130] test loss: 0.710
[10,   135] test loss: 0.717
[10,   140] test loss: 0.746
[10,   145] test loss: 0.730
[10,   150] test loss: 0.691
[10,   155] test loss: 0.738
[10,   160] test loss: 0.727
[10,   165] test loss: 0.708
[10,   170] test loss: 0.740
[10,   175] test loss: 0.712
[10,   180] test loss: 0.744
[10,   185] test loss: 0.725
[10,   190] test loss: 0.747
[10,   195] test loss: 0.709
[10,   200] test loss: 0.753
[10,   205] test loss: 0.710
[10,   210] test loss: 0.727
[10,   215] test loss: 0.734
[10,   220] test loss: 0.744
-----------------------------------------------------------------------------------------
Micro-Precision: 0.248720183968544, Macro-Precision: nan

Micro-Recall: 0.2758292853832245, Macro-Recall: nan

Micro-F1: 0.2615742087364197, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 160.24s | valid loss  0.73 | valid ppl     2.08
-----------------------------------------------------------------------------------------
[11,     5] train loss: 0.729
[11,    10] train loss: 0.725
[11,    15] train loss: 0.740
[11,    20] train loss: 0.727
[11,    25] train loss: 0.738
[11,    30] train loss: 0.720
[11,    35] train loss: 0.723
[11,    40] train loss: 0.749
[11,    45] train loss: 0.734
[11,    50] train loss: 0.739
[11,    55] train loss: 0.744
[11,    60] train loss: 0.740
[11,    65] train loss: 0.749
[11,    70] train loss: 0.726
[11,    75] train loss: 0.759
[11,    80] train loss: 0.747
[11,    85] train loss: 0.741
[11,    90] train loss: 0.729
[11,    95] train loss: 0.746
[11,   100] train loss: 0.760
[11,   105] train loss: 0.746
[11,   110] train loss: 0.734
[11,   115] train loss: 0.732
[11,   120] train loss: 0.731
[11,   125] train loss: 0.728
[11,   130] train loss: 0.736
[11,   135] train loss: 0.715
[11,   140] train loss: 0.735
[11,   145] train loss: 0.730
[11,   150] train loss: 0.743
[11,   155] train loss: 0.751
[11,   160] train loss: 0.755
[11,   165] train loss: 0.739
[11,   170] train loss: 0.719
[11,   175] train loss: 0.743
[11,   180] train loss: 0.736
[11,   185] train loss: 0.731
[11,   190] train loss: 0.726
[11,   195] train loss: 0.743
[11,   200] train loss: 0.731
[11,   205] train loss: 0.758
[11,   210] train loss: 0.729
[11,   215] train loss: 0.748
[11,   220] train loss: 0.732
[11,   225] train loss: 0.721
[11,   230] train loss: 0.767
[11,   235] train loss: 0.746
[11,   240] train loss: 0.729
[11,   245] train loss: 0.726
[11,   250] train loss: 0.750
[11,   255] train loss: 0.774
[11,   260] train loss: 0.736
[11,   265] train loss: 0.749
[11,   270] train loss: 0.734
[11,   275] train loss: 0.742
[11,   280] train loss: 0.735
[11,   285] train loss: 0.759
[11,   290] train loss: 0.740
[11,   295] train loss: 0.743
[11,   300] train loss: 0.731
[11,   305] train loss: 0.740
[11,   310] train loss: 0.752
[11,   315] train loss: 0.722
[11,   320] train loss: 0.736
[11,   325] train loss: 0.702
[11,   330] train loss: 0.725
[11,   335] train loss: 0.730
[11,   340] train loss: 0.731
[11,   345] train loss: 0.750
[11,   350] train loss: 0.746
[11,   355] train loss: 0.726
[11,   360] train loss: 0.740
[11,   365] train loss: 0.743
[11,   370] train loss: 0.738
[11,   375] train loss: 0.739
[11,   380] train loss: 0.712
[11,   385] train loss: 0.715
[11,   390] train loss: 0.752
[11,   395] train loss: 0.732
[11,   400] train loss: 0.740
[11,   405] train loss: 0.734
[11,   410] train loss: 0.730
[11,   415] train loss: 0.728
[11,   420] train loss: 0.753
[11,   425] train loss: 0.731
[11,   430] train loss: 0.739
[11,   435] train loss: 0.738
[11,   440] train loss: 0.753
[11,   445] train loss: 0.732
[11,   450] train loss: 0.736
[11,   455] train loss: 0.742
[11,   460] train loss: 0.750
[11,   465] train loss: 0.744
[11,   470] train loss: 0.727
[11,   475] train loss: 0.732
[11,   480] train loss: 0.743
[11,   485] train loss: 0.741
[11,   490] train loss: 0.745
[11,   495] train loss: 0.740
[11,   500] train loss: 0.724
[11,   505] train loss: 0.760
[11,   510] train loss: 0.745
[11,   515] train loss: 0.746
[11,   520] train loss: 0.732
[11,   525] train loss: 0.743
[11,   530] train loss: 0.740
[11,   535] train loss: 0.735
[11,   540] train loss: 0.724
[11,   545] train loss: 0.759
[11,   550] train loss: 0.736
[11,   555] train loss: 0.720
[11,   560] train loss: 0.736
[11,   565] train loss: 0.733
[11,   570] train loss: 0.732
[11,   575] train loss: 0.749
[11,   580] train loss: 0.738
[11,   585] train loss: 0.724
[11,   590] train loss: 0.761
[11,   595] train loss: 0.738
[11,   600] train loss: 0.740
[11,   605] train loss: 0.735
[11,   610] train loss: 0.736
[11,   615] train loss: 0.718
[11,   620] train loss: 0.740
[11,   625] train loss: 0.721
[11,   630] train loss: 0.744
[11,   635] train loss: 0.715
[11,   640] train loss: 0.738
[11,   645] train loss: 0.706
[11,   650] train loss: 0.743
[11,   655] train loss: 0.753
Finished Training
[11,     5] test loss: 0.740
[11,    10] test loss: 0.705
[11,    15] test loss: 0.719
[11,    20] test loss: 0.749
[11,    25] test loss: 0.746
[11,    30] test loss: 0.716
[11,    35] test loss: 0.723
[11,    40] test loss: 0.698
[11,    45] test loss: 0.732
[11,    50] test loss: 0.711
[11,    55] test loss: 0.732
[11,    60] test loss: 0.748
[11,    65] test loss: 0.735
[11,    70] test loss: 0.722
[11,    75] test loss: 0.696
[11,    80] test loss: 0.720
[11,    85] test loss: 0.734
[11,    90] test loss: 0.685
[11,    95] test loss: 0.706
[11,   100] test loss: 0.708
[11,   105] test loss: 0.711
[11,   110] test loss: 0.705
[11,   115] test loss: 0.716
[11,   120] test loss: 0.734
[11,   125] test loss: 0.717
[11,   130] test loss: 0.721
[11,   135] test loss: 0.734
[11,   140] test loss: 0.671
[11,   145] test loss: 0.731
[11,   150] test loss: 0.745
[11,   155] test loss: 0.722
[11,   160] test loss: 0.718
[11,   165] test loss: 0.737
[11,   170] test loss: 0.731
[11,   175] test loss: 0.725
[11,   180] test loss: 0.745
[11,   185] test loss: 0.692
[11,   190] test loss: 0.694
[11,   195] test loss: 0.725
[11,   200] test loss: 0.719
[11,   205] test loss: 0.731
[11,   210] test loss: 0.726
[11,   215] test loss: 0.700
[11,   220] test loss: 0.702
-----------------------------------------------------------------------------------------
Micro-Precision: 0.2566996216773987, Macro-Precision: nan

Micro-Recall: 0.2816002666950226, Macro-Recall: nan

Micro-F1: 0.2685740292072296, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 159.66s | valid loss  0.72 | valid ppl     2.06
-----------------------------------------------------------------------------------------
[12,     5] train loss: 0.718
[12,    10] train loss: 0.724
[12,    15] train loss: 0.746
[12,    20] train loss: 0.746
[12,    25] train loss: 0.738
[12,    30] train loss: 0.733
[12,    35] train loss: 0.733
[12,    40] train loss: 0.721
[12,    45] train loss: 0.741
[12,    50] train loss: 0.735
[12,    55] train loss: 0.730
[12,    60] train loss: 0.744
[12,    65] train loss: 0.748
[12,    70] train loss: 0.716
[12,    75] train loss: 0.746
[12,    80] train loss: 0.735
[12,    85] train loss: 0.740
[12,    90] train loss: 0.716
[12,    95] train loss: 0.730
[12,   100] train loss: 0.726
[12,   105] train loss: 0.724
[12,   110] train loss: 0.726
[12,   115] train loss: 0.737
[12,   120] train loss: 0.734
[12,   125] train loss: 0.731
[12,   130] train loss: 0.717
[12,   135] train loss: 0.739
[12,   140] train loss: 0.730
[12,   145] train loss: 0.743
[12,   150] train loss: 0.718
[12,   155] train loss: 0.730
[12,   160] train loss: 0.735
[12,   165] train loss: 0.746
[12,   170] train loss: 0.716
[12,   175] train loss: 0.727
[12,   180] train loss: 0.731
[12,   185] train loss: 0.729
[12,   190] train loss: 0.734
[12,   195] train loss: 0.744
[12,   200] train loss: 0.730
[12,   205] train loss: 0.718
[12,   210] train loss: 0.736
[12,   215] train loss: 0.732
[12,   220] train loss: 0.741
[12,   225] train loss: 0.714
[12,   230] train loss: 0.729
[12,   235] train loss: 0.751
[12,   240] train loss: 0.725
[12,   245] train loss: 0.717
[12,   250] train loss: 0.709
[12,   255] train loss: 0.745
[12,   260] train loss: 0.731
[12,   265] train loss: 0.750
[12,   270] train loss: 0.714
[12,   275] train loss: 0.705
[12,   280] train loss: 0.740
[12,   285] train loss: 0.699
[12,   290] train loss: 0.718
[12,   295] train loss: 0.719
[12,   300] train loss: 0.708
[12,   305] train loss: 0.716
[12,   310] train loss: 0.720
[12,   315] train loss: 0.755
[12,   320] train loss: 0.729
[12,   325] train loss: 0.717
[12,   330] train loss: 0.740
[12,   335] train loss: 0.725
[12,   340] train loss: 0.712
[12,   345] train loss: 0.734
[12,   350] train loss: 0.740
[12,   355] train loss: 0.723
[12,   360] train loss: 0.725
[12,   365] train loss: 0.737
[12,   370] train loss: 0.752
[12,   375] train loss: 0.731
[12,   380] train loss: 0.724
[12,   385] train loss: 0.723
[12,   390] train loss: 0.709
[12,   395] train loss: 0.734
[12,   400] train loss: 0.705
[12,   405] train loss: 0.722
[12,   410] train loss: 0.730
[12,   415] train loss: 0.716
[12,   420] train loss: 0.719
[12,   425] train loss: 0.730
[12,   430] train loss: 0.732
[12,   435] train loss: 0.732
[12,   440] train loss: 0.726
[12,   445] train loss: 0.735
[12,   450] train loss: 0.744
[12,   455] train loss: 0.728
[12,   460] train loss: 0.720
[12,   465] train loss: 0.717
[12,   470] train loss: 0.730
[12,   475] train loss: 0.745
[12,   480] train loss: 0.731
[12,   485] train loss: 0.728
[12,   490] train loss: 0.725
[12,   495] train loss: 0.738
[12,   500] train loss: 0.733
[12,   505] train loss: 0.714
[12,   510] train loss: 0.739
[12,   515] train loss: 0.733
[12,   520] train loss: 0.737
[12,   525] train loss: 0.725
[12,   530] train loss: 0.727
[12,   535] train loss: 0.723
[12,   540] train loss: 0.720
[12,   545] train loss: 0.737
[12,   550] train loss: 0.704
[12,   555] train loss: 0.720
[12,   560] train loss: 0.745
[12,   565] train loss: 0.748
[12,   570] train loss: 0.720
[12,   575] train loss: 0.735
[12,   580] train loss: 0.734
[12,   585] train loss: 0.721
[12,   590] train loss: 0.727
[12,   595] train loss: 0.740
[12,   600] train loss: 0.724
[12,   605] train loss: 0.707
[12,   610] train loss: 0.735
[12,   615] train loss: 0.728
[12,   620] train loss: 0.732
[12,   625] train loss: 0.722
[12,   630] train loss: 0.740
[12,   635] train loss: 0.705
[12,   640] train loss: 0.726
[12,   645] train loss: 0.735
[12,   650] train loss: 0.736
[12,   655] train loss: 0.729
Finished Training
[12,     5] test loss: 0.719
[12,    10] test loss: 0.725
[12,    15] test loss: 0.724
[12,    20] test loss: 0.710
[12,    25] test loss: 0.711
[12,    30] test loss: 0.686
[12,    35] test loss: 0.698
[12,    40] test loss: 0.736
[12,    45] test loss: 0.697
[12,    50] test loss: 0.732
[12,    55] test loss: 0.713
[12,    60] test loss: 0.705
[12,    65] test loss: 0.721
[12,    70] test loss: 0.710
[12,    75] test loss: 0.710
[12,    80] test loss: 0.723
[12,    85] test loss: 0.736
[12,    90] test loss: 0.696
[12,    95] test loss: 0.700
[12,   100] test loss: 0.712
[12,   105] test loss: 0.720
[12,   110] test loss: 0.712
[12,   115] test loss: 0.708
[12,   120] test loss: 0.723
[12,   125] test loss: 0.712
[12,   130] test loss: 0.695
[12,   135] test loss: 0.699
[12,   140] test loss: 0.737
[12,   145] test loss: 0.718
[12,   150] test loss: 0.692
[12,   155] test loss: 0.709
[12,   160] test loss: 0.711
[12,   165] test loss: 0.721
[12,   170] test loss: 0.713
[12,   175] test loss: 0.711
[12,   180] test loss: 0.693
[12,   185] test loss: 0.718
[12,   190] test loss: 0.707
[12,   195] test loss: 0.739
[12,   200] test loss: 0.728
[12,   205] test loss: 0.709
[12,   210] test loss: 0.709
[12,   215] test loss: 0.701
[12,   220] test loss: 0.712
-----------------------------------------------------------------------------------------
Micro-Precision: 0.26327869296073914, Macro-Precision: nan

Micro-Recall: 0.27691203355789185, Macro-Recall: nan

Micro-F1: 0.2699233293533325, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  11 | time: 158.64s | valid loss  0.72 | valid ppl     2.05
-----------------------------------------------------------------------------------------
[13,     5] train loss: 0.697
[13,    10] train loss: 0.725
[13,    15] train loss: 0.720
[13,    20] train loss: 0.740
[13,    25] train loss: 0.720
[13,    30] train loss: 0.718
[13,    35] train loss: 0.717
[13,    40] train loss: 0.714
[13,    45] train loss: 0.717
[13,    50] train loss: 0.723
[13,    55] train loss: 0.693
[13,    60] train loss: 0.716
[13,    65] train loss: 0.716
[13,    70] train loss: 0.726
[13,    75] train loss: 0.714
[13,    80] train loss: 0.720
[13,    85] train loss: 0.709
[13,    90] train loss: 0.707
[13,    95] train loss: 0.728
[13,   100] train loss: 0.729
[13,   105] train loss: 0.720
[13,   110] train loss: 0.720
[13,   115] train loss: 0.720
[13,   120] train loss: 0.731
[13,   125] train loss: 0.737
[13,   130] train loss: 0.711
[13,   135] train loss: 0.703
[13,   140] train loss: 0.749
[13,   145] train loss: 0.724
[13,   150] train loss: 0.700
[13,   155] train loss: 0.709
[13,   160] train loss: 0.728
[13,   165] train loss: 0.725
[13,   170] train loss: 0.727
[13,   175] train loss: 0.727
[13,   180] train loss: 0.743
[13,   185] train loss: 0.719
[13,   190] train loss: 0.718
[13,   195] train loss: 0.719
[13,   200] train loss: 0.723
[13,   205] train loss: 0.751
[13,   210] train loss: 0.722
[13,   215] train loss: 0.707
[13,   220] train loss: 0.738
[13,   225] train loss: 0.723
[13,   230] train loss: 0.705
[13,   235] train loss: 0.709
[13,   240] train loss: 0.723
[13,   245] train loss: 0.717
[13,   250] train loss: 0.727
[13,   255] train loss: 0.737
[13,   260] train loss: 0.733
[13,   265] train loss: 0.737
[13,   270] train loss: 0.719
[13,   275] train loss: 0.709
[13,   280] train loss: 0.710
[13,   285] train loss: 0.711
[13,   290] train loss: 0.740
[13,   295] train loss: 0.736
[13,   300] train loss: 0.717
[13,   305] train loss: 0.709
[13,   310] train loss: 0.727
[13,   315] train loss: 0.721
[13,   320] train loss: 0.711
[13,   325] train loss: 0.711
[13,   330] train loss: 0.717
[13,   335] train loss: 0.701
[13,   340] train loss: 0.733
[13,   345] train loss: 0.710
[13,   350] train loss: 0.728
[13,   355] train loss: 0.738
[13,   360] train loss: 0.741
[13,   365] train loss: 0.732
[13,   370] train loss: 0.714
[13,   375] train loss: 0.721
[13,   380] train loss: 0.723
[13,   385] train loss: 0.719
[13,   390] train loss: 0.717
[13,   395] train loss: 0.730
[13,   400] train loss: 0.730
[13,   405] train loss: 0.721
[13,   410] train loss: 0.713
[13,   415] train loss: 0.733
[13,   420] train loss: 0.721
[13,   425] train loss: 0.727
[13,   430] train loss: 0.718
[13,   435] train loss: 0.727
[13,   440] train loss: 0.703
[13,   445] train loss: 0.730
[13,   450] train loss: 0.727
[13,   455] train loss: 0.716
[13,   460] train loss: 0.715
[13,   465] train loss: 0.739
[13,   470] train loss: 0.720
[13,   475] train loss: 0.731
[13,   480] train loss: 0.746
[13,   485] train loss: 0.711
[13,   490] train loss: 0.731
[13,   495] train loss: 0.751
[13,   500] train loss: 0.709
[13,   505] train loss: 0.716
[13,   510] train loss: 0.730
[13,   515] train loss: 0.725
[13,   520] train loss: 0.701
[13,   525] train loss: 0.695
[13,   530] train loss: 0.715
[13,   535] train loss: 0.729
[13,   540] train loss: 0.708
[13,   545] train loss: 0.733
[13,   550] train loss: 0.698
[13,   555] train loss: 0.715
[13,   560] train loss: 0.710
[13,   565] train loss: 0.728
[13,   570] train loss: 0.712
[13,   575] train loss: 0.702
[13,   580] train loss: 0.718
[13,   585] train loss: 0.699
[13,   590] train loss: 0.712
[13,   595] train loss: 0.730
[13,   600] train loss: 0.734
[13,   605] train loss: 0.742
[13,   610] train loss: 0.721
[13,   615] train loss: 0.714
[13,   620] train loss: 0.725
[13,   625] train loss: 0.672
[13,   630] train loss: 0.731
[13,   635] train loss: 0.718
[13,   640] train loss: 0.737
[13,   645] train loss: 0.734
[13,   650] train loss: 0.707
[13,   655] train loss: 0.744
Finished Training
[13,     5] test loss: 0.674
[13,    10] test loss: 0.707
[13,    15] test loss: 0.689
[13,    20] test loss: 0.734
[13,    25] test loss: 0.716
[13,    30] test loss: 0.710
[13,    35] test loss: 0.703
[13,    40] test loss: 0.699
[13,    45] test loss: 0.696
[13,    50] test loss: 0.719
[13,    55] test loss: 0.679
[13,    60] test loss: 0.696
[13,    65] test loss: 0.708
[13,    70] test loss: 0.698
[13,    75] test loss: 0.712
[13,    80] test loss: 0.683
[13,    85] test loss: 0.693
[13,    90] test loss: 0.704
[13,    95] test loss: 0.706
[13,   100] test loss: 0.718
[13,   105] test loss: 0.719
[13,   110] test loss: 0.699
[13,   115] test loss: 0.695
[13,   120] test loss: 0.708
[13,   125] test loss: 0.702
[13,   130] test loss: 0.712
[13,   135] test loss: 0.707
[13,   140] test loss: 0.707
[13,   145] test loss: 0.717
[13,   150] test loss: 0.698
[13,   155] test loss: 0.697
[13,   160] test loss: 0.722
[13,   165] test loss: 0.703
[13,   170] test loss: 0.715
[13,   175] test loss: 0.729
[13,   180] test loss: 0.667
[13,   185] test loss: 0.725
[13,   190] test loss: 0.714
[13,   195] test loss: 0.696
[13,   200] test loss: 0.698
[13,   205] test loss: 0.718
[13,   210] test loss: 0.729
[13,   215] test loss: 0.730
[13,   220] test loss: 0.722
-----------------------------------------------------------------------------------------
Micro-Precision: 0.2691321074962616, Macro-Precision: nan

Micro-Recall: 0.28252217173576355, Macro-Recall: nan

Micro-F1: 0.27566462755203247, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  12 | time: 158.80s | valid loss  0.71 | valid ppl     2.03
-----------------------------------------------------------------------------------------
[14,     5] train loss: 0.729
[14,    10] train loss: 0.720
[14,    15] train loss: 0.707
[14,    20] train loss: 0.702
[14,    25] train loss: 0.730
[14,    30] train loss: 0.696
[14,    35] train loss: 0.707
[14,    40] train loss: 0.706
[14,    45] train loss: 0.711
[14,    50] train loss: 0.713
[14,    55] train loss: 0.712
[14,    60] train loss: 0.705
[14,    65] train loss: 0.710
[14,    70] train loss: 0.711
[14,    75] train loss: 0.718
[14,    80] train loss: 0.714
[14,    85] train loss: 0.702
[14,    90] train loss: 0.699
[14,    95] train loss: 0.713
[14,   100] train loss: 0.717
[14,   105] train loss: 0.730
[14,   110] train loss: 0.737
[14,   115] train loss: 0.714
[14,   120] train loss: 0.711
[14,   125] train loss: 0.718
[14,   130] train loss: 0.690
[14,   135] train loss: 0.717
[14,   140] train loss: 0.728
[14,   145] train loss: 0.721
[14,   150] train loss: 0.706
[14,   155] train loss: 0.729
[14,   160] train loss: 0.728
[14,   165] train loss: 0.739
[14,   170] train loss: 0.731
[14,   175] train loss: 0.709
[14,   180] train loss: 0.718
[14,   185] train loss: 0.706
[14,   190] train loss: 0.707
[14,   195] train loss: 0.724
[14,   200] train loss: 0.711
[14,   205] train loss: 0.717
[14,   210] train loss: 0.711
[14,   215] train loss: 0.722
[14,   220] train loss: 0.678
[14,   225] train loss: 0.725
[14,   230] train loss: 0.695
[14,   235] train loss: 0.700
[14,   240] train loss: 0.730
[14,   245] train loss: 0.735
[14,   250] train loss: 0.730
[14,   255] train loss: 0.732
[14,   260] train loss: 0.705
[14,   265] train loss: 0.719
[14,   270] train loss: 0.716
[14,   275] train loss: 0.731
[14,   280] train loss: 0.731
[14,   285] train loss: 0.707
[14,   290] train loss: 0.701
[14,   295] train loss: 0.706
[14,   300] train loss: 0.715
[14,   305] train loss: 0.730
[14,   310] train loss: 0.713
[14,   315] train loss: 0.731
[14,   320] train loss: 0.725
[14,   325] train loss: 0.703
[14,   330] train loss: 0.745
[14,   335] train loss: 0.709
[14,   340] train loss: 0.720
[14,   345] train loss: 0.723
[14,   350] train loss: 0.695
[14,   355] train loss: 0.706
[14,   360] train loss: 0.740
[14,   365] train loss: 0.700
[14,   370] train loss: 0.721
[14,   375] train loss: 0.724
[14,   380] train loss: 0.696
[14,   385] train loss: 0.711
[14,   390] train loss: 0.720
[14,   395] train loss: 0.708
[14,   400] train loss: 0.693
[14,   405] train loss: 0.684
[14,   410] train loss: 0.707
[14,   415] train loss: 0.701
[14,   420] train loss: 0.732
[14,   425] train loss: 0.713
[14,   430] train loss: 0.712
[14,   435] train loss: 0.703
[14,   440] train loss: 0.719
[14,   445] train loss: 0.718
[14,   450] train loss: 0.711
[14,   455] train loss: 0.719
[14,   460] train loss: 0.695
[14,   465] train loss: 0.719
[14,   470] train loss: 0.707
[14,   475] train loss: 0.697
[14,   480] train loss: 0.714
[14,   485] train loss: 0.706
[14,   490] train loss: 0.704
[14,   495] train loss: 0.695
[14,   500] train loss: 0.693
[14,   505] train loss: 0.713
[14,   510] train loss: 0.707
[14,   515] train loss: 0.710
[14,   520] train loss: 0.692
[14,   525] train loss: 0.709
[14,   530] train loss: 0.719
[14,   535] train loss: 0.734
[14,   540] train loss: 0.725
[14,   545] train loss: 0.728
[14,   550] train loss: 0.721
[14,   555] train loss: 0.702
[14,   560] train loss: 0.690
[14,   565] train loss: 0.722
[14,   570] train loss: 0.714
[14,   575] train loss: 0.727
[14,   580] train loss: 0.702
[14,   585] train loss: 0.711
[14,   590] train loss: 0.683
[14,   595] train loss: 0.738
[14,   600] train loss: 0.695
[14,   605] train loss: 0.730
[14,   610] train loss: 0.701
[14,   615] train loss: 0.706
[14,   620] train loss: 0.727
[14,   625] train loss: 0.741
[14,   630] train loss: 0.704
[14,   635] train loss: 0.690
[14,   640] train loss: 0.726
[14,   645] train loss: 0.703
[14,   650] train loss: 0.708
[14,   655] train loss: 0.727
Finished Training
[14,     5] test loss: 0.688
[14,    10] test loss: 0.710
[14,    15] test loss: 0.689
[14,    20] test loss: 0.718
[14,    25] test loss: 0.691
[14,    30] test loss: 0.698
[14,    35] test loss: 0.694
[14,    40] test loss: 0.714
[14,    45] test loss: 0.690
[14,    50] test loss: 0.711
[14,    55] test loss: 0.705
[14,    60] test loss: 0.693
[14,    65] test loss: 0.713
[14,    70] test loss: 0.695
[14,    75] test loss: 0.722
[14,    80] test loss: 0.684
[14,    85] test loss: 0.711
[14,    90] test loss: 0.686
[14,    95] test loss: 0.696
[14,   100] test loss: 0.670
[14,   105] test loss: 0.714
[14,   110] test loss: 0.693
[14,   115] test loss: 0.722
[14,   120] test loss: 0.684
[14,   125] test loss: 0.671
[14,   130] test loss: 0.698
[14,   135] test loss: 0.707
[14,   140] test loss: 0.735
[14,   145] test loss: 0.703
[14,   150] test loss: 0.693
[14,   155] test loss: 0.714
[14,   160] test loss: 0.707
[14,   165] test loss: 0.685
[14,   170] test loss: 0.705
[14,   175] test loss: 0.689
[14,   180] test loss: 0.715
[14,   185] test loss: 0.746
[14,   190] test loss: 0.700
[14,   195] test loss: 0.681
[14,   200] test loss: 0.682
[14,   205] test loss: 0.688
[14,   210] test loss: 0.702
[14,   215] test loss: 0.694
[14,   220] test loss: 0.703
-----------------------------------------------------------------------------------------
Micro-Precision: 0.27671611309051514, Macro-Precision: nan

Micro-Recall: 0.2934420108795166, Macro-Recall: nan

Micro-F1: 0.28483372926712036, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  13 | time: 158.64s | valid loss  0.70 | valid ppl     2.02
-----------------------------------------------------------------------------------------
[15,     5] train loss: 0.740
[15,    10] train loss: 0.716
[15,    15] train loss: 0.703
[15,    20] train loss: 0.712
[15,    25] train loss: 0.699
[15,    30] train loss: 0.700
[15,    35] train loss: 0.722
[15,    40] train loss: 0.710
[15,    45] train loss: 0.694
[15,    50] train loss: 0.711
[15,    55] train loss: 0.719
[15,    60] train loss: 0.694
[15,    65] train loss: 0.690
[15,    70] train loss: 0.707
[15,    75] train loss: 0.702
[15,    80] train loss: 0.726
[15,    85] train loss: 0.722
[15,    90] train loss: 0.685
[15,    95] train loss: 0.708
[15,   100] train loss: 0.691
[15,   105] train loss: 0.725
[15,   110] train loss: 0.689
[15,   115] train loss: 0.711
[15,   120] train loss: 0.705
[15,   125] train loss: 0.710
[15,   130] train loss: 0.717
[15,   135] train loss: 0.723
[15,   140] train loss: 0.700
[15,   145] train loss: 0.705
[15,   150] train loss: 0.718
[15,   155] train loss: 0.727
[15,   160] train loss: 0.707
[15,   165] train loss: 0.701
[15,   170] train loss: 0.724
[15,   175] train loss: 0.693
[15,   180] train loss: 0.720
[15,   185] train loss: 0.717
[15,   190] train loss: 0.678
[15,   195] train loss: 0.715
[15,   200] train loss: 0.704
[15,   205] train loss: 0.691
[15,   210] train loss: 0.703
[15,   215] train loss: 0.690
[15,   220] train loss: 0.732
[15,   225] train loss: 0.707
[15,   230] train loss: 0.716
[15,   235] train loss: 0.727
[15,   240] train loss: 0.720
[15,   245] train loss: 0.705
[15,   250] train loss: 0.705
[15,   255] train loss: 0.688
[15,   260] train loss: 0.698
[15,   265] train loss: 0.696
[15,   270] train loss: 0.690
[15,   275] train loss: 0.701
[15,   280] train loss: 0.719
[15,   285] train loss: 0.729
[15,   290] train loss: 0.708
[15,   295] train loss: 0.699
[15,   300] train loss: 0.686
[15,   305] train loss: 0.709
[15,   310] train loss: 0.707
[15,   315] train loss: 0.723
[15,   320] train loss: 0.709
[15,   325] train loss: 0.717
[15,   330] train loss: 0.712
[15,   335] train loss: 0.707
[15,   340] train loss: 0.700
[15,   345] train loss: 0.724
[15,   350] train loss: 0.695
[15,   355] train loss: 0.699
[15,   360] train loss: 0.723
[15,   365] train loss: 0.680
[15,   370] train loss: 0.707
[15,   375] train loss: 0.709
[15,   380] train loss: 0.700
[15,   385] train loss: 0.700
[15,   390] train loss: 0.725
[15,   395] train loss: 0.716
[15,   400] train loss: 0.687
[15,   405] train loss: 0.721
[15,   410] train loss: 0.703
[15,   415] train loss: 0.725
[15,   420] train loss: 0.685
[15,   425] train loss: 0.719
[15,   430] train loss: 0.685
[15,   435] train loss: 0.702
[15,   440] train loss: 0.730
[15,   445] train loss: 0.719
[15,   450] train loss: 0.693
[15,   455] train loss: 0.700
[15,   460] train loss: 0.704
[15,   465] train loss: 0.691
[15,   470] train loss: 0.710
[15,   475] train loss: 0.720
[15,   480] train loss: 0.692
[15,   485] train loss: 0.708
[15,   490] train loss: 0.696
[15,   495] train loss: 0.691
[15,   500] train loss: 0.697
[15,   505] train loss: 0.700
[15,   510] train loss: 0.712
[15,   515] train loss: 0.715
[15,   520] train loss: 0.709
[15,   525] train loss: 0.712
[15,   530] train loss: 0.696
[15,   535] train loss: 0.696
[15,   540] train loss: 0.684
[15,   545] train loss: 0.690
[15,   550] train loss: 0.713
[15,   555] train loss: 0.690
[15,   560] train loss: 0.719
[15,   565] train loss: 0.706
[15,   570] train loss: 0.681
[15,   575] train loss: 0.708
[15,   580] train loss: 0.697
[15,   585] train loss: 0.700
[15,   590] train loss: 0.693
[15,   595] train loss: 0.707
[15,   600] train loss: 0.719
[15,   605] train loss: 0.722
[15,   610] train loss: 0.730
[15,   615] train loss: 0.694
[15,   620] train loss: 0.695
[15,   625] train loss: 0.710
[15,   630] train loss: 0.690
[15,   635] train loss: 0.673
[15,   640] train loss: 0.718
[15,   645] train loss: 0.718
[15,   650] train loss: 0.710
[15,   655] train loss: 0.720
Finished Training
[15,     5] test loss: 0.698
[15,    10] test loss: 0.724
[15,    15] test loss: 0.689
[15,    20] test loss: 0.686
[15,    25] test loss: 0.670
[15,    30] test loss: 0.699
[15,    35] test loss: 0.683
[15,    40] test loss: 0.724
[15,    45] test loss: 0.665
[15,    50] test loss: 0.708
[15,    55] test loss: 0.704
[15,    60] test loss: 0.710
[15,    65] test loss: 0.663
[15,    70] test loss: 0.686
[15,    75] test loss: 0.693
[15,    80] test loss: 0.714
[15,    85] test loss: 0.709
[15,    90] test loss: 0.719
[15,    95] test loss: 0.719
[15,   100] test loss: 0.717
[15,   105] test loss: 0.727
[15,   110] test loss: 0.686
[15,   115] test loss: 0.683
[15,   120] test loss: 0.696
[15,   125] test loss: 0.664
[15,   130] test loss: 0.694
[15,   135] test loss: 0.683
[15,   140] test loss: 0.706
[15,   145] test loss: 0.677
[15,   150] test loss: 0.697
[15,   155] test loss: 0.687
[15,   160] test loss: 0.688
[15,   165] test loss: 0.701
[15,   170] test loss: 0.723
[15,   175] test loss: 0.685
[15,   180] test loss: 0.686
[15,   185] test loss: 0.675
[15,   190] test loss: 0.693
[15,   195] test loss: 0.705
[15,   200] test loss: 0.682
[15,   205] test loss: 0.703
[15,   210] test loss: 0.693
[15,   215] test loss: 0.679
[15,   220] test loss: 0.682
-----------------------------------------------------------------------------------------
Micro-Precision: 0.2813432812690735, Macro-Precision: nan

Micro-Recall: 0.29922157526016235, Macro-Recall: nan

Micro-F1: 0.29000717401504517, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  14 | time: 158.54s | valid loss  0.70 | valid ppl     2.01
-----------------------------------------------------------------------------------------
[16,     5] train loss: 0.725
[16,    10] train loss: 0.704
[16,    15] train loss: 0.702
[16,    20] train loss: 0.689
[16,    25] train loss: 0.682
[16,    30] train loss: 0.693
[16,    35] train loss: 0.680
[16,    40] train loss: 0.707
[16,    45] train loss: 0.721
[16,    50] train loss: 0.687
[16,    55] train loss: 0.706
[16,    60] train loss: 0.690
[16,    65] train loss: 0.704
[16,    70] train loss: 0.694
[16,    75] train loss: 0.705
[16,    80] train loss: 0.700
[16,    85] train loss: 0.710
[16,    90] train loss: 0.701
[16,    95] train loss: 0.703
[16,   100] train loss: 0.686
[16,   105] train loss: 0.710
[16,   110] train loss: 0.698
[16,   115] train loss: 0.709
[16,   120] train loss: 0.713
[16,   125] train loss: 0.688
[16,   130] train loss: 0.707
[16,   135] train loss: 0.718
[16,   140] train loss: 0.691
[16,   145] train loss: 0.712
[16,   150] train loss: 0.712
[16,   155] train loss: 0.693
[16,   160] train loss: 0.709
[16,   165] train loss: 0.720
[16,   170] train loss: 0.681
[16,   175] train loss: 0.694
[16,   180] train loss: 0.679
[16,   185] train loss: 0.704
[16,   190] train loss: 0.693
[16,   195] train loss: 0.683
[16,   200] train loss: 0.706
[16,   205] train loss: 0.700
[16,   210] train loss: 0.703
[16,   215] train loss: 0.712
[16,   220] train loss: 0.718
[16,   225] train loss: 0.694
[16,   230] train loss: 0.701
[16,   235] train loss: 0.702
[16,   240] train loss: 0.688
[16,   245] train loss: 0.717
[16,   250] train loss: 0.712
[16,   255] train loss: 0.709
[16,   260] train loss: 0.710
[16,   265] train loss: 0.706
[16,   270] train loss: 0.707
[16,   275] train loss: 0.674
[16,   280] train loss: 0.700
[16,   285] train loss: 0.718
[16,   290] train loss: 0.693
[16,   295] train loss: 0.698
[16,   300] train loss: 0.688
[16,   305] train loss: 0.694
[16,   310] train loss: 0.698
[16,   315] train loss: 0.710
[16,   320] train loss: 0.689
[16,   325] train loss: 0.702
[16,   330] train loss: 0.715
[16,   335] train loss: 0.704
[16,   340] train loss: 0.695
[16,   345] train loss: 0.712
[16,   350] train loss: 0.726
[16,   355] train loss: 0.684
[16,   360] train loss: 0.690
[16,   365] train loss: 0.696
[16,   370] train loss: 0.702
[16,   375] train loss: 0.687
[16,   380] train loss: 0.685
[16,   385] train loss: 0.728
[16,   390] train loss: 0.676
[16,   395] train loss: 0.686
[16,   400] train loss: 0.687
[16,   405] train loss: 0.704
[16,   410] train loss: 0.720
[16,   415] train loss: 0.704
[16,   420] train loss: 0.678
[16,   425] train loss: 0.708
[16,   430] train loss: 0.708
[16,   435] train loss: 0.705
[16,   440] train loss: 0.688
[16,   445] train loss: 0.694
[16,   450] train loss: 0.694
[16,   455] train loss: 0.727
[16,   460] train loss: 0.695
[16,   465] train loss: 0.685
[16,   470] train loss: 0.698
[16,   475] train loss: 0.715
[16,   480] train loss: 0.693
[16,   485] train loss: 0.705
[16,   490] train loss: 0.708
[16,   495] train loss: 0.700
[16,   500] train loss: 0.688
[16,   505] train loss: 0.714
[16,   510] train loss: 0.670
[16,   515] train loss: 0.703
[16,   520] train loss: 0.706
[16,   525] train loss: 0.718
[16,   530] train loss: 0.703
[16,   535] train loss: 0.713
[16,   540] train loss: 0.691
[16,   545] train loss: 0.707
[16,   550] train loss: 0.700
[16,   555] train loss: 0.696
[16,   560] train loss: 0.696
[16,   565] train loss: 0.691
[16,   570] train loss: 0.694
[16,   575] train loss: 0.712
[16,   580] train loss: 0.724
[16,   585] train loss: 0.681
[16,   590] train loss: 0.688
[16,   595] train loss: 0.684
[16,   600] train loss: 0.674
[16,   605] train loss: 0.695
[16,   610] train loss: 0.686
[16,   615] train loss: 0.710
[16,   620] train loss: 0.694
[16,   625] train loss: 0.713
[16,   630] train loss: 0.697
[16,   635] train loss: 0.691
[16,   640] train loss: 0.694
[16,   645] train loss: 0.678
[16,   650] train loss: 0.703
[16,   655] train loss: 0.708
Finished Training
[16,     5] test loss: 0.673
[16,    10] test loss: 0.676
[16,    15] test loss: 0.703
[16,    20] test loss: 0.692
[16,    25] test loss: 0.697
[16,    30] test loss: 0.697
[16,    35] test loss: 0.695
[16,    40] test loss: 0.676
[16,    45] test loss: 0.714
[16,    50] test loss: 0.711
[16,    55] test loss: 0.678
[16,    60] test loss: 0.698
[16,    65] test loss: 0.656
[16,    70] test loss: 0.681
[16,    75] test loss: 0.709
[16,    80] test loss: 0.747
[16,    85] test loss: 0.687
[16,    90] test loss: 0.700
[16,    95] test loss: 0.687
[16,   100] test loss: 0.681
[16,   105] test loss: 0.676
[16,   110] test loss: 0.713
[16,   115] test loss: 0.667
[16,   120] test loss: 0.669
[16,   125] test loss: 0.685
[16,   130] test loss: 0.644
[16,   135] test loss: 0.688
[16,   140] test loss: 0.733
[16,   145] test loss: 0.687
[16,   150] test loss: 0.693
[16,   155] test loss: 0.683
[16,   160] test loss: 0.700
[16,   165] test loss: 0.712
[16,   170] test loss: 0.717
[16,   175] test loss: 0.657
[16,   180] test loss: 0.664
[16,   185] test loss: 0.709
[16,   190] test loss: 0.697
[16,   195] test loss: 0.692
[16,   200] test loss: 0.691
[16,   205] test loss: 0.687
[16,   210] test loss: 0.687
[16,   215] test loss: 0.684
[16,   220] test loss: 0.680
-----------------------------------------------------------------------------------------
Micro-Precision: 0.2863450050354004, Macro-Precision: nan

Micro-Recall: 0.3169553875923157, Macro-Recall: nan

Micro-F1: 0.30087363719940186, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  15 | time: 159.65s | valid loss  0.69 | valid ppl     2.00
-----------------------------------------------------------------------------------------
[17,     5] train loss: 0.672
[17,    10] train loss: 0.686
[17,    15] train loss: 0.700
[17,    20] train loss: 0.699
[17,    25] train loss: 0.688
[17,    30] train loss: 0.676
[17,    35] train loss: 0.673
[17,    40] train loss: 0.705
[17,    45] train loss: 0.676
[17,    50] train loss: 0.712
[17,    55] train loss: 0.704
[17,    60] train loss: 0.701
[17,    65] train loss: 0.694
[17,    70] train loss: 0.698
[17,    75] train loss: 0.687
[17,    80] train loss: 0.690
[17,    85] train loss: 0.671
[17,    90] train loss: 0.701
[17,    95] train loss: 0.683
[17,   100] train loss: 0.684
[17,   105] train loss: 0.711
[17,   110] train loss: 0.702
[17,   115] train loss: 0.671
[17,   120] train loss: 0.694
[17,   125] train loss: 0.677
[17,   130] train loss: 0.700
[17,   135] train loss: 0.680
[17,   140] train loss: 0.681
[17,   145] train loss: 0.682
[17,   150] train loss: 0.707
[17,   155] train loss: 0.672
[17,   160] train loss: 0.688
[17,   165] train loss: 0.705
[17,   170] train loss: 0.718
[17,   175] train loss: 0.686
[17,   180] train loss: 0.678
[17,   185] train loss: 0.685
[17,   190] train loss: 0.717
[17,   195] train loss: 0.690
[17,   200] train loss: 0.702
[17,   205] train loss: 0.682
[17,   210] train loss: 0.715
[17,   215] train loss: 0.681
[17,   220] train loss: 0.686
[17,   225] train loss: 0.697
[17,   230] train loss: 0.692
[17,   235] train loss: 0.692
[17,   240] train loss: 0.675
[17,   245] train loss: 0.687
[17,   250] train loss: 0.688
[17,   255] train loss: 0.700
[17,   260] train loss: 0.705
[17,   265] train loss: 0.699
[17,   270] train loss: 0.690
[17,   275] train loss: 0.694
[17,   280] train loss: 0.681
[17,   285] train loss: 0.705
[17,   290] train loss: 0.685
[17,   295] train loss: 0.707
[17,   300] train loss: 0.701
[17,   305] train loss: 0.705
[17,   310] train loss: 0.685
[17,   315] train loss: 0.692
[17,   320] train loss: 0.684
[17,   325] train loss: 0.691
[17,   330] train loss: 0.673
[17,   335] train loss: 0.676
[17,   340] train loss: 0.706
[17,   345] train loss: 0.722
[17,   350] train loss: 0.694
[17,   355] train loss: 0.695
[17,   360] train loss: 0.698
[17,   365] train loss: 0.701
[17,   370] train loss: 0.696
[17,   375] train loss: 0.699
[17,   380] train loss: 0.687
[17,   385] train loss: 0.715
[17,   390] train loss: 0.708
[17,   395] train loss: 0.701
[17,   400] train loss: 0.675
[17,   405] train loss: 0.687
[17,   410] train loss: 0.677
[17,   415] train loss: 0.732
[17,   420] train loss: 0.728
[17,   425] train loss: 0.694
[17,   430] train loss: 0.707
[17,   435] train loss: 0.688
[17,   440] train loss: 0.690
[17,   445] train loss: 0.694
[17,   450] train loss: 0.693
[17,   455] train loss: 0.693
[17,   460] train loss: 0.709
[17,   465] train loss: 0.700
[17,   470] train loss: 0.705
[17,   475] train loss: 0.693
[17,   480] train loss: 0.700
[17,   485] train loss: 0.698
[17,   490] train loss: 0.695
[17,   495] train loss: 0.686
[17,   500] train loss: 0.701
[17,   505] train loss: 0.709
[17,   510] train loss: 0.699
[17,   515] train loss: 0.685
[17,   520] train loss: 0.694
[17,   525] train loss: 0.713
[17,   530] train loss: 0.682
[17,   535] train loss: 0.687
[17,   540] train loss: 0.667
[17,   545] train loss: 0.696
[17,   550] train loss: 0.686
[17,   555] train loss: 0.696
[17,   560] train loss: 0.701
[17,   565] train loss: 0.696
[17,   570] train loss: 0.709
[17,   575] train loss: 0.699
[17,   580] train loss: 0.698
[17,   585] train loss: 0.706
[17,   590] train loss: 0.697
[17,   595] train loss: 0.692
[17,   600] train loss: 0.672
[17,   605] train loss: 0.692
[17,   610] train loss: 0.691
[17,   615] train loss: 0.673
[17,   620] train loss: 0.666
[17,   625] train loss: 0.695
[17,   630] train loss: 0.691
[17,   635] train loss: 0.699
[17,   640] train loss: 0.680
[17,   645] train loss: 0.670
[17,   650] train loss: 0.690
[17,   655] train loss: 0.693
Finished Training
[17,     5] test loss: 0.682
[17,    10] test loss: 0.653
[17,    15] test loss: 0.684
[17,    20] test loss: 0.681
[17,    25] test loss: 0.663
[17,    30] test loss: 0.685
[17,    35] test loss: 0.669
[17,    40] test loss: 0.691
[17,    45] test loss: 0.700
[17,    50] test loss: 0.694
[17,    55] test loss: 0.718
[17,    60] test loss: 0.712
[17,    65] test loss: 0.703
[17,    70] test loss: 0.689
[17,    75] test loss: 0.665
[17,    80] test loss: 0.668
[17,    85] test loss: 0.680
[17,    90] test loss: 0.687
[17,    95] test loss: 0.662
[17,   100] test loss: 0.700
[17,   105] test loss: 0.709
[17,   110] test loss: 0.682
[17,   115] test loss: 0.690
[17,   120] test loss: 0.682
[17,   125] test loss: 0.702
[17,   130] test loss: 0.702
[17,   135] test loss: 0.674
[17,   140] test loss: 0.683
[17,   145] test loss: 0.695
[17,   150] test loss: 0.686
[17,   155] test loss: 0.668
[17,   160] test loss: 0.678
[17,   165] test loss: 0.682
[17,   170] test loss: 0.671
[17,   175] test loss: 0.702
[17,   180] test loss: 0.720
[17,   185] test loss: 0.680
[17,   190] test loss: 0.695
[17,   195] test loss: 0.720
[17,   200] test loss: 0.682
[17,   205] test loss: 0.667
[17,   210] test loss: 0.683
[17,   215] test loss: 0.671
[17,   220] test loss: 0.679
-----------------------------------------------------------------------------------------
Micro-Precision: 0.29061123728752136, Macro-Precision: nan

Micro-Recall: 0.31458503007888794, Macro-Recall: nan

Micro-F1: 0.3021233081817627, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  16 | time: 159.85s | valid loss  0.69 | valid ppl     1.99
-----------------------------------------------------------------------------------------
[18,     5] train loss: 0.696
[18,    10] train loss: 0.692
[18,    15] train loss: 0.724
[18,    20] train loss: 0.714
[18,    25] train loss: 0.666
[18,    30] train loss: 0.683
[18,    35] train loss: 0.674
[18,    40] train loss: 0.710
[18,    45] train loss: 0.682
[18,    50] train loss: 0.692
[18,    55] train loss: 0.680
[18,    60] train loss: 0.690
[18,    65] train loss: 0.676
[18,    70] train loss: 0.678
[18,    75] train loss: 0.702
[18,    80] train loss: 0.707
[18,    85] train loss: 0.691
[18,    90] train loss: 0.661
[18,    95] train loss: 0.692
[18,   100] train loss: 0.670
[18,   105] train loss: 0.687
[18,   110] train loss: 0.703
[18,   115] train loss: 0.695
[18,   120] train loss: 0.701
[18,   125] train loss: 0.701
[18,   130] train loss: 0.682
[18,   135] train loss: 0.684
[18,   140] train loss: 0.690
[18,   145] train loss: 0.703
[18,   150] train loss: 0.669
[18,   155] train loss: 0.670
[18,   160] train loss: 0.686
[18,   165] train loss: 0.674
[18,   170] train loss: 0.705
[18,   175] train loss: 0.677
[18,   180] train loss: 0.668
[18,   185] train loss: 0.652
[18,   190] train loss: 0.666
[18,   195] train loss: 0.730
[18,   200] train loss: 0.679
[18,   205] train loss: 0.667
[18,   210] train loss: 0.679
[18,   215] train loss: 0.693
[18,   220] train loss: 0.684
[18,   225] train loss: 0.699
[18,   230] train loss: 0.706
[18,   235] train loss: 0.696
[18,   240] train loss: 0.684
[18,   245] train loss: 0.672
[18,   250] train loss: 0.688
[18,   255] train loss: 0.685
[18,   260] train loss: 0.695
[18,   265] train loss: 0.717
[18,   270] train loss: 0.686
[18,   275] train loss: 0.705
[18,   280] train loss: 0.690
[18,   285] train loss: 0.676
[18,   290] train loss: 0.695
[18,   295] train loss: 0.672
[18,   300] train loss: 0.682
[18,   305] train loss: 0.688
[18,   310] train loss: 0.693
[18,   315] train loss: 0.686
[18,   320] train loss: 0.693
[18,   325] train loss: 0.692
[18,   330] train loss: 0.684
[18,   335] train loss: 0.683
[18,   340] train loss: 0.690
[18,   345] train loss: 0.695
[18,   350] train loss: 0.666
[18,   355] train loss: 0.695
[18,   360] train loss: 0.674
[18,   365] train loss: 0.676
[18,   370] train loss: 0.707
[18,   375] train loss: 0.714
[18,   380] train loss: 0.687
[18,   385] train loss: 0.663
[18,   390] train loss: 0.692
[18,   395] train loss: 0.682
[18,   400] train loss: 0.667
[18,   405] train loss: 0.697
[18,   410] train loss: 0.716
[18,   415] train loss: 0.699
[18,   420] train loss: 0.681
[18,   425] train loss: 0.679
[18,   430] train loss: 0.697
[18,   435] train loss: 0.682
[18,   440] train loss: 0.687
[18,   445] train loss: 0.677
[18,   450] train loss: 0.713
[18,   455] train loss: 0.688
[18,   460] train loss: 0.672
[18,   465] train loss: 0.669
[18,   470] train loss: 0.680
[18,   475] train loss: 0.672
[18,   480] train loss: 0.679
[18,   485] train loss: 0.708
[18,   490] train loss: 0.702
[18,   495] train loss: 0.681
[18,   500] train loss: 0.671
[18,   505] train loss: 0.681
[18,   510] train loss: 0.707
[18,   515] train loss: 0.710
[18,   520] train loss: 0.698
[18,   525] train loss: 0.705
[18,   530] train loss: 0.682
[18,   535] train loss: 0.691
[18,   540] train loss: 0.696
[18,   545] train loss: 0.669
[18,   550] train loss: 0.704
[18,   555] train loss: 0.669
[18,   560] train loss: 0.668
[18,   565] train loss: 0.701
[18,   570] train loss: 0.674
[18,   575] train loss: 0.698
[18,   580] train loss: 0.678
[18,   585] train loss: 0.687
[18,   590] train loss: 0.701
[18,   595] train loss: 0.662
[18,   600] train loss: 0.663
[18,   605] train loss: 0.669
[18,   610] train loss: 0.692
[18,   615] train loss: 0.694
[18,   620] train loss: 0.690
[18,   625] train loss: 0.673
[18,   630] train loss: 0.674
[18,   635] train loss: 0.685
[18,   640] train loss: 0.686
[18,   645] train loss: 0.701
[18,   650] train loss: 0.679
[18,   655] train loss: 0.660
Finished Training
[18,     5] test loss: 0.686
[18,    10] test loss: 0.676
[18,    15] test loss: 0.663
[18,    20] test loss: 0.701
[18,    25] test loss: 0.677
[18,    30] test loss: 0.672
[18,    35] test loss: 0.656
[18,    40] test loss: 0.667
[18,    45] test loss: 0.653
[18,    50] test loss: 0.709
[18,    55] test loss: 0.670
[18,    60] test loss: 0.678
[18,    65] test loss: 0.724
[18,    70] test loss: 0.691
[18,    75] test loss: 0.639
[18,    80] test loss: 0.688
[18,    85] test loss: 0.721
[18,    90] test loss: 0.681
[18,    95] test loss: 0.685
[18,   100] test loss: 0.697
[18,   105] test loss: 0.644
[18,   110] test loss: 0.680
[18,   115] test loss: 0.710
[18,   120] test loss: 0.697
[18,   125] test loss: 0.686
[18,   130] test loss: 0.705
[18,   135] test loss: 0.677
[18,   140] test loss: 0.694
[18,   145] test loss: 0.641
[18,   150] test loss: 0.681
[18,   155] test loss: 0.640
[18,   160] test loss: 0.686
[18,   165] test loss: 0.635
[18,   170] test loss: 0.677
[18,   175] test loss: 0.699
[18,   180] test loss: 0.692
[18,   185] test loss: 0.706
[18,   190] test loss: 0.679
[18,   195] test loss: 0.695
[18,   200] test loss: 0.700
[18,   205] test loss: 0.661
[18,   210] test loss: 0.692
[18,   215] test loss: 0.701
[18,   220] test loss: 0.685
-----------------------------------------------------------------------------------------
Micro-Precision: 0.295955091714859, Macro-Precision: nan

Micro-Recall: 0.32716843485832214, Macro-Recall: nan

Micro-F1: 0.31078001856803894, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  17 | time: 160.73s | valid loss  0.68 | valid ppl     1.98
-----------------------------------------------------------------------------------------
[19,     5] train loss: 0.682
[19,    10] train loss: 0.682
[19,    15] train loss: 0.696
[19,    20] train loss: 0.689
[19,    25] train loss: 0.685
[19,    30] train loss: 0.686
[19,    35] train loss: 0.698
[19,    40] train loss: 0.671
[19,    45] train loss: 0.683
[19,    50] train loss: 0.698
[19,    55] train loss: 0.685
[19,    60] train loss: 0.680
[19,    65] train loss: 0.673
[19,    70] train loss: 0.680
[19,    75] train loss: 0.669
[19,    80] train loss: 0.678
[19,    85] train loss: 0.683
[19,    90] train loss: 0.666
[19,    95] train loss: 0.691
[19,   100] train loss: 0.693
[19,   105] train loss: 0.669
[19,   110] train loss: 0.710
[19,   115] train loss: 0.692
[19,   120] train loss: 0.668
[19,   125] train loss: 0.692
[19,   130] train loss: 0.683
[19,   135] train loss: 0.667
[19,   140] train loss: 0.683
[19,   145] train loss: 0.688
[19,   150] train loss: 0.689
[19,   155] train loss: 0.659
[19,   160] train loss: 0.693
[19,   165] train loss: 0.675
[19,   170] train loss: 0.674
[19,   175] train loss: 0.690
[19,   180] train loss: 0.653
[19,   185] train loss: 0.688
[19,   190] train loss: 0.675
[19,   195] train loss: 0.662
[19,   200] train loss: 0.698
[19,   205] train loss: 0.680
[19,   210] train loss: 0.679
[19,   215] train loss: 0.667
[19,   220] train loss: 0.679
[19,   225] train loss: 0.687
[19,   230] train loss: 0.678
[19,   235] train loss: 0.686
[19,   240] train loss: 0.689
[19,   245] train loss: 0.668
[19,   250] train loss: 0.702
[19,   255] train loss: 0.689
[19,   260] train loss: 0.698
[19,   265] train loss: 0.686
[19,   270] train loss: 0.706
[19,   275] train loss: 0.703
[19,   280] train loss: 0.679
[19,   285] train loss: 0.679
[19,   290] train loss: 0.659
[19,   295] train loss: 0.661
[19,   300] train loss: 0.692
[19,   305] train loss: 0.673
[19,   310] train loss: 0.698
[19,   315] train loss: 0.699
[19,   320] train loss: 0.692
[19,   325] train loss: 0.668
[19,   330] train loss: 0.677
[19,   335] train loss: 0.682
[19,   340] train loss: 0.653
[19,   345] train loss: 0.693
[19,   350] train loss: 0.699
[19,   355] train loss: 0.698
[19,   360] train loss: 0.668
[19,   365] train loss: 0.660
[19,   370] train loss: 0.683
[19,   375] train loss: 0.698
[19,   380] train loss: 0.688
[19,   385] train loss: 0.669
[19,   390] train loss: 0.696
[19,   395] train loss: 0.682
[19,   400] train loss: 0.683
[19,   405] train loss: 0.696
[19,   410] train loss: 0.674
[19,   415] train loss: 0.681
[19,   420] train loss: 0.663
[19,   425] train loss: 0.695
[19,   430] train loss: 0.695
[19,   435] train loss: 0.661
[19,   440] train loss: 0.696
[19,   445] train loss: 0.685
[19,   450] train loss: 0.686
[19,   455] train loss: 0.708
[19,   460] train loss: 0.662
[19,   465] train loss: 0.704
[19,   470] train loss: 0.691
[19,   475] train loss: 0.672
[19,   480] train loss: 0.685
[19,   485] train loss: 0.676
[19,   490] train loss: 0.676
[19,   495] train loss: 0.686
[19,   500] train loss: 0.663
[19,   505] train loss: 0.671
[19,   510] train loss: 0.681
[19,   515] train loss: 0.674
[19,   520] train loss: 0.698
[19,   525] train loss: 0.670
[19,   530] train loss: 0.688
[19,   535] train loss: 0.682
[19,   540] train loss: 0.671
[19,   545] train loss: 0.672
[19,   550] train loss: 0.702
[19,   555] train loss: 0.676
[19,   560] train loss: 0.667
[19,   565] train loss: 0.691
[19,   570] train loss: 0.687
[19,   575] train loss: 0.665
[19,   580] train loss: 0.676
[19,   585] train loss: 0.668
[19,   590] train loss: 0.667
[19,   595] train loss: 0.703
[19,   600] train loss: 0.680
[19,   605] train loss: 0.661
[19,   610] train loss: 0.661
[19,   615] train loss: 0.686
[19,   620] train loss: 0.679
[19,   625] train loss: 0.683
[19,   630] train loss: 0.661
[19,   635] train loss: 0.657
[19,   640] train loss: 0.677
[19,   645] train loss: 0.669
[19,   650] train loss: 0.687
[19,   655] train loss: 0.687
Finished Training
[19,     5] test loss: 0.696
[19,    10] test loss: 0.693
[19,    15] test loss: 0.687
[19,    20] test loss: 0.667
[19,    25] test loss: 0.674
[19,    30] test loss: 0.678
[19,    35] test loss: 0.645
[19,    40] test loss: 0.653
[19,    45] test loss: 0.693
[19,    50] test loss: 0.660
[19,    55] test loss: 0.653
[19,    60] test loss: 0.674
[19,    65] test loss: 0.723
[19,    70] test loss: 0.676
[19,    75] test loss: 0.664
[19,    80] test loss: 0.653
[19,    85] test loss: 0.680
[19,    90] test loss: 0.687
[19,    95] test loss: 0.658
[19,   100] test loss: 0.663
[19,   105] test loss: 0.693
[19,   110] test loss: 0.710
[19,   115] test loss: 0.675
[19,   120] test loss: 0.711
[19,   125] test loss: 0.662
[19,   130] test loss: 0.702
[19,   135] test loss: 0.680
[19,   140] test loss: 0.674
[19,   145] test loss: 0.690
[19,   150] test loss: 0.701
[19,   155] test loss: 0.669
[19,   160] test loss: 0.697
[19,   165] test loss: 0.689
[19,   170] test loss: 0.648
[19,   175] test loss: 0.636
[19,   180] test loss: 0.642
[19,   185] test loss: 0.660
[19,   190] test loss: 0.644
[19,   195] test loss: 0.674
[19,   200] test loss: 0.677
[19,   205] test loss: 0.680
[19,   210] test loss: 0.715
[19,   215] test loss: 0.700
[19,   220] test loss: 0.671
-----------------------------------------------------------------------------------------
Micro-Precision: 0.302142858505249, Macro-Precision: nan

Micro-Recall: 0.3071824610233307, Macro-Recall: nan

Micro-F1: 0.30464181303977966, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  18 | time: 157.85s | valid loss  0.68 | valid ppl     1.97
-----------------------------------------------------------------------------------------
[20,     5] train loss: 0.672
[20,    10] train loss: 0.673
[20,    15] train loss: 0.687
[20,    20] train loss: 0.664
[20,    25] train loss: 0.685
[20,    30] train loss: 0.663
[20,    35] train loss: 0.679
[20,    40] train loss: 0.670
[20,    45] train loss: 0.671
[20,    50] train loss: 0.663
[20,    55] train loss: 0.666
[20,    60] train loss: 0.686
[20,    65] train loss: 0.677
[20,    70] train loss: 0.660
[20,    75] train loss: 0.700
[20,    80] train loss: 0.672
[20,    85] train loss: 0.670
[20,    90] train loss: 0.667
[20,    95] train loss: 0.663
[20,   100] train loss: 0.677
[20,   105] train loss: 0.673
[20,   110] train loss: 0.688
[20,   115] train loss: 0.711
[20,   120] train loss: 0.677
[20,   125] train loss: 0.700
[20,   130] train loss: 0.679
[20,   135] train loss: 0.677
[20,   140] train loss: 0.687
[20,   145] train loss: 0.674
[20,   150] train loss: 0.680
[20,   155] train loss: 0.672
[20,   160] train loss: 0.668
[20,   165] train loss: 0.670
[20,   170] train loss: 0.691
[20,   175] train loss: 0.657
[20,   180] train loss: 0.694
[20,   185] train loss: 0.687
[20,   190] train loss: 0.678
[20,   195] train loss: 0.664
[20,   200] train loss: 0.667
[20,   205] train loss: 0.667
[20,   210] train loss: 0.669
[20,   215] train loss: 0.667
[20,   220] train loss: 0.680
[20,   225] train loss: 0.683
[20,   230] train loss: 0.659
[20,   235] train loss: 0.682
[20,   240] train loss: 0.666
[20,   245] train loss: 0.666
[20,   250] train loss: 0.676
[20,   255] train loss: 0.654
[20,   260] train loss: 0.669
[20,   265] train loss: 0.689
[20,   270] train loss: 0.644
[20,   275] train loss: 0.659
[20,   280] train loss: 0.688
[20,   285] train loss: 0.691
[20,   290] train loss: 0.660
[20,   295] train loss: 0.678
[20,   300] train loss: 0.674
[20,   305] train loss: 0.662
[20,   310] train loss: 0.693
[20,   315] train loss: 0.667
[20,   320] train loss: 0.692
[20,   325] train loss: 0.706
[20,   330] train loss: 0.679
[20,   335] train loss: 0.667
[20,   340] train loss: 0.669
[20,   345] train loss: 0.665
[20,   350] train loss: 0.673
[20,   355] train loss: 0.670
[20,   360] train loss: 0.671
[20,   365] train loss: 0.659
[20,   370] train loss: 0.675
[20,   375] train loss: 0.654
[20,   380] train loss: 0.652
[20,   385] train loss: 0.685
[20,   390] train loss: 0.664
[20,   395] train loss: 0.680
[20,   400] train loss: 0.685
[20,   405] train loss: 0.676
[20,   410] train loss: 0.663
[20,   415] train loss: 0.676
[20,   420] train loss: 0.654
[20,   425] train loss: 0.671
[20,   430] train loss: 0.667
[20,   435] train loss: 0.667
[20,   440] train loss: 0.674
[20,   445] train loss: 0.698
[20,   450] train loss: 0.675
[20,   455] train loss: 0.689
[20,   460] train loss: 0.653
[20,   465] train loss: 0.689
[20,   470] train loss: 0.685
[20,   475] train loss: 0.664
[20,   480] train loss: 0.677
[20,   485] train loss: 0.680
[20,   490] train loss: 0.673
[20,   495] train loss: 0.684
[20,   500] train loss: 0.693
[20,   505] train loss: 0.676
[20,   510] train loss: 0.683
[20,   515] train loss: 0.654
[20,   520] train loss: 0.676
[20,   525] train loss: 0.659
[20,   530] train loss: 0.678
[20,   535] train loss: 0.658
[20,   540] train loss: 0.690
[20,   545] train loss: 0.674
[20,   550] train loss: 0.673
[20,   555] train loss: 0.681
[20,   560] train loss: 0.696
[20,   565] train loss: 0.681
[20,   570] train loss: 0.696
[20,   575] train loss: 0.711
[20,   580] train loss: 0.652
[20,   585] train loss: 0.666
[20,   590] train loss: 0.654
[20,   595] train loss: 0.659
[20,   600] train loss: 0.675
[20,   605] train loss: 0.663
[20,   610] train loss: 0.677
[20,   615] train loss: 0.677
[20,   620] train loss: 0.679
[20,   625] train loss: 0.673
[20,   630] train loss: 0.684
[20,   635] train loss: 0.708
[20,   640] train loss: 0.705
[20,   645] train loss: 0.671
[20,   650] train loss: 0.697
[20,   655] train loss: 0.662
Finished Training
[20,     5] test loss: 0.666
[20,    10] test loss: 0.681
[20,    15] test loss: 0.680
[20,    20] test loss: 0.664
[20,    25] test loss: 0.652
[20,    30] test loss: 0.702
[20,    35] test loss: 0.689
[20,    40] test loss: 0.656
[20,    45] test loss: 0.658
[20,    50] test loss: 0.701
[20,    55] test loss: 0.672
[20,    60] test loss: 0.687
[20,    65] test loss: 0.647
[20,    70] test loss: 0.690
[20,    75] test loss: 0.664
[20,    80] test loss: 0.646
[20,    85] test loss: 0.681
[20,    90] test loss: 0.694
[20,    95] test loss: 0.689
[20,   100] test loss: 0.662
[20,   105] test loss: 0.693
[20,   110] test loss: 0.675
[20,   115] test loss: 0.669
[20,   120] test loss: 0.663
[20,   125] test loss: 0.680
[20,   130] test loss: 0.647
[20,   135] test loss: 0.670
[20,   140] test loss: 0.666
[20,   145] test loss: 0.699
[20,   150] test loss: 0.661
[20,   155] test loss: 0.657
[20,   160] test loss: 0.673
[20,   165] test loss: 0.668
[20,   170] test loss: 0.659
[20,   175] test loss: 0.651
[20,   180] test loss: 0.639
[20,   185] test loss: 0.639
[20,   190] test loss: 0.676
[20,   195] test loss: 0.686
[20,   200] test loss: 0.672
[20,   205] test loss: 0.705
[20,   210] test loss: 0.648
[20,   215] test loss: 0.700
[20,   220] test loss: 0.700
-----------------------------------------------------------------------------------------
Micro-Precision: 0.30397698283195496, Macro-Precision: nan

Micro-Recall: 0.31860944628715515, Macro-Recall: nan

Micro-F1: 0.31112128496170044, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  19 | time: 159.36s | valid loss  0.68 | valid ppl     1.96
-----------------------------------------------------------------------------------------
[21,     5] train loss: 0.663
[21,    10] train loss: 0.683
[21,    15] train loss: 0.679
[21,    20] train loss: 0.691
[21,    25] train loss: 0.677
[21,    30] train loss: 0.654
[21,    35] train loss: 0.675
[21,    40] train loss: 0.661
[21,    45] train loss: 0.668
[21,    50] train loss: 0.668
[21,    55] train loss: 0.678
[21,    60] train loss: 0.699
[21,    65] train loss: 0.673
[21,    70] train loss: 0.669
[21,    75] train loss: 0.693
[21,    80] train loss: 0.678
[21,    85] train loss: 0.681
[21,    90] train loss: 0.668
[21,    95] train loss: 0.676
[21,   100] train loss: 0.684
[21,   105] train loss: 0.675
[21,   110] train loss: 0.679
[21,   115] train loss: 0.653
[21,   120] train loss: 0.660
[21,   125] train loss: 0.680
[21,   130] train loss: 0.657
[21,   135] train loss: 0.668
[21,   140] train loss: 0.684
[21,   145] train loss: 0.662
[21,   150] train loss: 0.661
[21,   155] train loss: 0.668
[21,   160] train loss: 0.669
[21,   165] train loss: 0.682
[21,   170] train loss: 0.653
[21,   175] train loss: 0.668
[21,   180] train loss: 0.661
[21,   185] train loss: 0.669
[21,   190] train loss: 0.682
[21,   195] train loss: 0.669
[21,   200] train loss: 0.718
[21,   205] train loss: 0.664
[21,   210] train loss: 0.641
[21,   215] train loss: 0.678
[21,   220] train loss: 0.678
[21,   225] train loss: 0.678
[21,   230] train loss: 0.658
[21,   235] train loss: 0.674
[21,   240] train loss: 0.684
[21,   245] train loss: 0.664
[21,   250] train loss: 0.675
[21,   255] train loss: 0.659
[21,   260] train loss: 0.647
[21,   265] train loss: 0.666
[21,   270] train loss: 0.661
[21,   275] train loss: 0.681
[21,   280] train loss: 0.651
[21,   285] train loss: 0.662
[21,   290] train loss: 0.683
[21,   295] train loss: 0.644
[21,   300] train loss: 0.674
[21,   305] train loss: 0.673
[21,   310] train loss: 0.698
[21,   315] train loss: 0.657
[21,   320] train loss: 0.663
[21,   325] train loss: 0.673
[21,   330] train loss: 0.680
[21,   335] train loss: 0.689
[21,   340] train loss: 0.652
[21,   345] train loss: 0.670
[21,   350] train loss: 0.662
[21,   355] train loss: 0.649
[21,   360] train loss: 0.675
[21,   365] train loss: 0.676
[21,   370] train loss: 0.682
[21,   375] train loss: 0.687
[21,   380] train loss: 0.672
[21,   385] train loss: 0.665
[21,   390] train loss: 0.672
[21,   395] train loss: 0.691
[21,   400] train loss: 0.651
[21,   405] train loss: 0.665
[21,   410] train loss: 0.666
[21,   415] train loss: 0.681
[21,   420] train loss: 0.683
[21,   425] train loss: 0.690
[21,   430] train loss: 0.674
[21,   435] train loss: 0.670
[21,   440] train loss: 0.684
[21,   445] train loss: 0.650
[21,   450] train loss: 0.669
[21,   455] train loss: 0.660
[21,   460] train loss: 0.665
[21,   465] train loss: 0.661
[21,   470] train loss: 0.667
[21,   475] train loss: 0.693
[21,   480] train loss: 0.689
[21,   485] train loss: 0.680
[21,   490] train loss: 0.693
[21,   495] train loss: 0.676
[21,   500] train loss: 0.654
[21,   505] train loss: 0.679
[21,   510] train loss: 0.647
[21,   515] train loss: 0.665
[21,   520] train loss: 0.683
[21,   525] train loss: 0.652
[21,   530] train loss: 0.662
[21,   535] train loss: 0.658
[21,   540] train loss: 0.667
[21,   545] train loss: 0.665
[21,   550] train loss: 0.678
[21,   555] train loss: 0.647
[21,   560] train loss: 0.646
[21,   565] train loss: 0.681
[21,   570] train loss: 0.645
[21,   575] train loss: 0.670
[21,   580] train loss: 0.683
[21,   585] train loss: 0.648
[21,   590] train loss: 0.678
[21,   595] train loss: 0.662
[21,   600] train loss: 0.684
[21,   605] train loss: 0.656
[21,   610] train loss: 0.667
[21,   615] train loss: 0.669
[21,   620] train loss: 0.660
[21,   625] train loss: 0.680
[21,   630] train loss: 0.679
[21,   635] train loss: 0.672
[21,   640] train loss: 0.654
[21,   645] train loss: 0.664
[21,   650] train loss: 0.662
[21,   655] train loss: 0.646
Finished Training
[21,     5] test loss: 0.647
[21,    10] test loss: 0.659
[21,    15] test loss: 0.663
[21,    20] test loss: 0.696
[21,    25] test loss: 0.650
[21,    30] test loss: 0.658
[21,    35] test loss: 0.671
[21,    40] test loss: 0.656
[21,    45] test loss: 0.685
[21,    50] test loss: 0.649
[21,    55] test loss: 0.666
[21,    60] test loss: 0.709
[21,    65] test loss: 0.666
[21,    70] test loss: 0.661
[21,    75] test loss: 0.677
[21,    80] test loss: 0.677
[21,    85] test loss: 0.671
[21,    90] test loss: 0.684
[21,    95] test loss: 0.655
[21,   100] test loss: 0.694
[21,   105] test loss: 0.680
[21,   110] test loss: 0.639
[21,   115] test loss: 0.651
[21,   120] test loss: 0.675
[21,   125] test loss: 0.669
[21,   130] test loss: 0.682
[21,   135] test loss: 0.652
[21,   140] test loss: 0.707
[21,   145] test loss: 0.675
[21,   150] test loss: 0.655
[21,   155] test loss: 0.681
[21,   160] test loss: 0.649
[21,   165] test loss: 0.666
[21,   170] test loss: 0.648
[21,   175] test loss: 0.655
[21,   180] test loss: 0.659
[21,   185] test loss: 0.717
[21,   190] test loss: 0.651
[21,   195] test loss: 0.672
[21,   200] test loss: 0.658
[21,   205] test loss: 0.693
[21,   210] test loss: 0.706
[21,   215] test loss: 0.698
[21,   220] test loss: 0.650
-----------------------------------------------------------------------------------------
Micro-Precision: 0.3053673505783081, Macro-Precision: nan

Micro-Recall: 0.3363133668899536, Macro-Recall: nan

Micro-F1: 0.32009413838386536, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  20 | time: 159.47s | valid loss  0.67 | valid ppl     1.96
-----------------------------------------------------------------------------------------
[22,     5] train loss: 0.645
[22,    10] train loss: 0.648
[22,    15] train loss: 0.665
[22,    20] train loss: 0.671
[22,    25] train loss: 0.673
[22,    30] train loss: 0.682
[22,    35] train loss: 0.656
[22,    40] train loss: 0.675
[22,    45] train loss: 0.676
[22,    50] train loss: 0.659
[22,    55] train loss: 0.655
[22,    60] train loss: 0.657
[22,    65] train loss: 0.639
[22,    70] train loss: 0.649
[22,    75] train loss: 0.657
[22,    80] train loss: 0.667
[22,    85] train loss: 0.671
[22,    90] train loss: 0.642
[22,    95] train loss: 0.657
[22,   100] train loss: 0.639
[22,   105] train loss: 0.655
[22,   110] train loss: 0.661
[22,   115] train loss: 0.674
[22,   120] train loss: 0.664
[22,   125] train loss: 0.664
[22,   130] train loss: 0.679
[22,   135] train loss: 0.651
[22,   140] train loss: 0.658
[22,   145] train loss: 0.654
[22,   150] train loss: 0.671
[22,   155] train loss: 0.675
[22,   160] train loss: 0.664
[22,   165] train loss: 0.662
[22,   170] train loss: 0.683
[22,   175] train loss: 0.678
[22,   180] train loss: 0.667
[22,   185] train loss: 0.673
[22,   190] train loss: 0.671
[22,   195] train loss: 0.663
[22,   200] train loss: 0.658
[22,   205] train loss: 0.657
[22,   210] train loss: 0.652
[22,   215] train loss: 0.669
[22,   220] train loss: 0.685
[22,   225] train loss: 0.672
[22,   230] train loss: 0.646
[22,   235] train loss: 0.674
[22,   240] train loss: 0.690
[22,   245] train loss: 0.672
[22,   250] train loss: 0.686
[22,   255] train loss: 0.672
[22,   260] train loss: 0.675
[22,   265] train loss: 0.683
[22,   270] train loss: 0.684
[22,   275] train loss: 0.650
[22,   280] train loss: 0.650
[22,   285] train loss: 0.652
[22,   290] train loss: 0.672
[22,   295] train loss: 0.666
[22,   300] train loss: 0.641
[22,   305] train loss: 0.664
[22,   310] train loss: 0.689
[22,   315] train loss: 0.682
[22,   320] train loss: 0.651
[22,   325] train loss: 0.656
[22,   330] train loss: 0.669
[22,   335] train loss: 0.659
[22,   340] train loss: 0.663
[22,   345] train loss: 0.655
[22,   350] train loss: 0.653
[22,   355] train loss: 0.677
[22,   360] train loss: 0.663
[22,   365] train loss: 0.651
[22,   370] train loss: 0.665
[22,   375] train loss: 0.669
[22,   380] train loss: 0.671
[22,   385] train loss: 0.645
[22,   390] train loss: 0.676
[22,   395] train loss: 0.662
[22,   400] train loss: 0.667
[22,   405] train loss: 0.654
[22,   410] train loss: 0.709
[22,   415] train loss: 0.705
[22,   420] train loss: 0.659
[22,   425] train loss: 0.672
[22,   430] train loss: 0.654
[22,   435] train loss: 0.642
[22,   440] train loss: 0.671
[22,   445] train loss: 0.668
[22,   450] train loss: 0.667
[22,   455] train loss: 0.686
[22,   460] train loss: 0.660
[22,   465] train loss: 0.664
[22,   470] train loss: 0.653
[22,   475] train loss: 0.687
[22,   480] train loss: 0.667
[22,   485] train loss: 0.670
[22,   490] train loss: 0.659
[22,   495] train loss: 0.657
[22,   500] train loss: 0.667
[22,   505] train loss: 0.679
[22,   510] train loss: 0.674
[22,   515] train loss: 0.665
[22,   520] train loss: 0.664
[22,   525] train loss: 0.654
[22,   530] train loss: 0.689
[22,   535] train loss: 0.664
[22,   540] train loss: 0.641
[22,   545] train loss: 0.649
[22,   550] train loss: 0.651
[22,   555] train loss: 0.673
[22,   560] train loss: 0.653
[22,   565] train loss: 0.660
[22,   570] train loss: 0.663
[22,   575] train loss: 0.666
[22,   580] train loss: 0.660
[22,   585] train loss: 0.669
[22,   590] train loss: 0.657
[22,   595] train loss: 0.671
[22,   600] train loss: 0.679
[22,   605] train loss: 0.670
[22,   610] train loss: 0.659
[22,   615] train loss: 0.682
[22,   620] train loss: 0.657
[22,   625] train loss: 0.667
[22,   630] train loss: 0.668
[22,   635] train loss: 0.660
[22,   640] train loss: 0.664
[22,   645] train loss: 0.629
[22,   650] train loss: 0.645
[22,   655] train loss: 0.671
Finished Training
[22,     5] test loss: 0.661
[22,    10] test loss: 0.666
[22,    15] test loss: 0.652
[22,    20] test loss: 0.640
[22,    25] test loss: 0.654
[22,    30] test loss: 0.624
[22,    35] test loss: 0.640
[22,    40] test loss: 0.672
[22,    45] test loss: 0.675
[22,    50] test loss: 0.666
[22,    55] test loss: 0.678
[22,    60] test loss: 0.648
[22,    65] test loss: 0.702
[22,    70] test loss: 0.644
[22,    75] test loss: 0.696
[22,    80] test loss: 0.672
[22,    85] test loss: 0.668
[22,    90] test loss: 0.661
[22,    95] test loss: 0.639
[22,   100] test loss: 0.688
[22,   105] test loss: 0.681
[22,   110] test loss: 0.665
[22,   115] test loss: 0.655
[22,   120] test loss: 0.656
[22,   125] test loss: 0.662
[22,   130] test loss: 0.705
[22,   135] test loss: 0.702
[22,   140] test loss: 0.652
[22,   145] test loss: 0.667
[22,   150] test loss: 0.678
[22,   155] test loss: 0.634
[22,   160] test loss: 0.687
[22,   165] test loss: 0.664
[22,   170] test loss: 0.680
[22,   175] test loss: 0.705
[22,   180] test loss: 0.670
[22,   185] test loss: 0.686
[22,   190] test loss: 0.664
[22,   195] test loss: 0.667
[22,   200] test loss: 0.672
[22,   205] test loss: 0.659
[22,   210] test loss: 0.638
[22,   215] test loss: 0.676
[22,   220] test loss: 0.668
-----------------------------------------------------------------------------------------
Micro-Precision: 0.3092223107814789, Macro-Precision: nan

Micro-Recall: 0.3305191397666931, Macro-Recall: nan

Micro-F1: 0.31951624155044556, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  21 | time: 158.96s | valid loss  0.67 | valid ppl     1.95
-----------------------------------------------------------------------------------------
[23,     5] train loss: 0.668
[23,    10] train loss: 0.659
[23,    15] train loss: 0.663
[23,    20] train loss: 0.634
[23,    25] train loss: 0.655
[23,    30] train loss: 0.659
[23,    35] train loss: 0.667
[23,    40] train loss: 0.666
[23,    45] train loss: 0.682
[23,    50] train loss: 0.643
[23,    55] train loss: 0.668
[23,    60] train loss: 0.635
[23,    65] train loss: 0.639
[23,    70] train loss: 0.643
[23,    75] train loss: 0.641
[23,    80] train loss: 0.666
[23,    85] train loss: 0.682
[23,    90] train loss: 0.663
[23,    95] train loss: 0.663
[23,   100] train loss: 0.650
[23,   105] train loss: 0.679
[23,   110] train loss: 0.684
[23,   115] train loss: 0.681
[23,   120] train loss: 0.663
[23,   125] train loss: 0.680
[23,   130] train loss: 0.656
[23,   135] train loss: 0.659
[23,   140] train loss: 0.639
[23,   145] train loss: 0.664
[23,   150] train loss: 0.636
[23,   155] train loss: 0.659
[23,   160] train loss: 0.672
[23,   165] train loss: 0.653
[23,   170] train loss: 0.681
[23,   175] train loss: 0.649
[23,   180] train loss: 0.656
[23,   185] train loss: 0.668
[23,   190] train loss: 0.663
[23,   195] train loss: 0.657
[23,   200] train loss: 0.657
[23,   205] train loss: 0.659
[23,   210] train loss: 0.671
[23,   215] train loss: 0.682
[23,   220] train loss: 0.671
[23,   225] train loss: 0.679
[23,   230] train loss: 0.642
[23,   235] train loss: 0.660
[23,   240] train loss: 0.650
[23,   245] train loss: 0.654
[23,   250] train loss: 0.659
[23,   255] train loss: 0.658
[23,   260] train loss: 0.644
[23,   265] train loss: 0.669
[23,   270] train loss: 0.682
[23,   275] train loss: 0.659
[23,   280] train loss: 0.651
[23,   285] train loss: 0.646
[23,   290] train loss: 0.662
[23,   295] train loss: 0.695
[23,   300] train loss: 0.665
[23,   305] train loss: 0.664
[23,   310] train loss: 0.650
[23,   315] train loss: 0.652
[23,   320] train loss: 0.652
[23,   325] train loss: 0.652
[23,   330] train loss: 0.668
[23,   335] train loss: 0.664
[23,   340] train loss: 0.667
[23,   345] train loss: 0.641
[23,   350] train loss: 0.652
[23,   355] train loss: 0.687
[23,   360] train loss: 0.651
[23,   365] train loss: 0.646
[23,   370] train loss: 0.647
[23,   375] train loss: 0.660
[23,   380] train loss: 0.655
[23,   385] train loss: 0.653
[23,   390] train loss: 0.661
[23,   395] train loss: 0.658
[23,   400] train loss: 0.644
[23,   405] train loss: 0.664
[23,   410] train loss: 0.642
[23,   415] train loss: 0.659
[23,   420] train loss: 0.620
[23,   425] train loss: 0.669
[23,   430] train loss: 0.644
[23,   435] train loss: 0.666
[23,   440] train loss: 0.680
[23,   445] train loss: 0.666
[23,   450] train loss: 0.644
[23,   455] train loss: 0.659
[23,   460] train loss: 0.668
[23,   465] train loss: 0.632
[23,   470] train loss: 0.660
[23,   475] train loss: 0.640
[23,   480] train loss: 0.670
[23,   485] train loss: 0.658
[23,   490] train loss: 0.659
[23,   495] train loss: 0.665
[23,   500] train loss: 0.669
[23,   505] train loss: 0.654
[23,   510] train loss: 0.667
[23,   515] train loss: 0.667
[23,   520] train loss: 0.682
[23,   525] train loss: 0.668
[23,   530] train loss: 0.652
[23,   535] train loss: 0.662
[23,   540] train loss: 0.668
[23,   545] train loss: 0.647
[23,   550] train loss: 0.663
[23,   555] train loss: 0.658
[23,   560] train loss: 0.662
[23,   565] train loss: 0.662
[23,   570] train loss: 0.664
[23,   575] train loss: 0.647
[23,   580] train loss: 0.641
[23,   585] train loss: 0.644
[23,   590] train loss: 0.674
[23,   595] train loss: 0.668
[23,   600] train loss: 0.664
[23,   605] train loss: 0.620
[23,   610] train loss: 0.656
[23,   615] train loss: 0.663
[23,   620] train loss: 0.647
[23,   625] train loss: 0.680
[23,   630] train loss: 0.648
[23,   635] train loss: 0.659
[23,   640] train loss: 0.646
[23,   645] train loss: 0.683
[23,   650] train loss: 0.667
[23,   655] train loss: 0.663
Finished Training
[23,     5] test loss: 0.681
[23,    10] test loss: 0.670
[23,    15] test loss: 0.690
[23,    20] test loss: 0.629
[23,    25] test loss: 0.665
[23,    30] test loss: 0.665
[23,    35] test loss: 0.666
[23,    40] test loss: 0.692
[23,    45] test loss: 0.666
[23,    50] test loss: 0.674
[23,    55] test loss: 0.647
[23,    60] test loss: 0.642
[23,    65] test loss: 0.657
[23,    70] test loss: 0.695
[23,    75] test loss: 0.682
[23,    80] test loss: 0.639
[23,    85] test loss: 0.634
[23,    90] test loss: 0.643
[23,    95] test loss: 0.647
[23,   100] test loss: 0.699
[23,   105] test loss: 0.667
[23,   110] test loss: 0.676
[23,   115] test loss: 0.685
[23,   120] test loss: 0.669
[23,   125] test loss: 0.650
[23,   130] test loss: 0.639
[23,   135] test loss: 0.681
[23,   140] test loss: 0.664
[23,   145] test loss: 0.658
[23,   150] test loss: 0.680
[23,   155] test loss: 0.669
[23,   160] test loss: 0.658
[23,   165] test loss: 0.650
[23,   170] test loss: 0.682
[23,   175] test loss: 0.646
[23,   180] test loss: 0.657
[23,   185] test loss: 0.651
[23,   190] test loss: 0.672
[23,   195] test loss: 0.685
[23,   200] test loss: 0.633
[23,   205] test loss: 0.660
[23,   210] test loss: 0.655
[23,   215] test loss: 0.657
[23,   220] test loss: 0.655
-----------------------------------------------------------------------------------------
Micro-Precision: 0.31484875082969666, Macro-Precision: nan

Micro-Recall: 0.3368496596813202, Macro-Recall: nan

Micro-F1: 0.32547783851623535, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  22 | time: 159.85s | valid loss  0.67 | valid ppl     1.95
-----------------------------------------------------------------------------------------
[24,     5] train loss: 0.628
[24,    10] train loss: 0.644
[24,    15] train loss: 0.644
[24,    20] train loss: 0.663
[24,    25] train loss: 0.632
[24,    30] train loss: 0.641
[24,    35] train loss: 0.658
[24,    40] train loss: 0.641
[24,    45] train loss: 0.649
[24,    50] train loss: 0.675
[24,    55] train loss: 0.644
[24,    60] train loss: 0.667
[24,    65] train loss: 0.653
[24,    70] train loss: 0.664
[24,    75] train loss: 0.673
[24,    80] train loss: 0.665
[24,    85] train loss: 0.637
[24,    90] train loss: 0.640
[24,    95] train loss: 0.681
[24,   100] train loss: 0.665
[24,   105] train loss: 0.655
[24,   110] train loss: 0.660
[24,   115] train loss: 0.666
[24,   120] train loss: 0.648
[24,   125] train loss: 0.655
[24,   130] train loss: 0.661
[24,   135] train loss: 0.639
[24,   140] train loss: 0.656
[24,   145] train loss: 0.656
[24,   150] train loss: 0.653
[24,   155] train loss: 0.657
[24,   160] train loss: 0.687
[24,   165] train loss: 0.650
[24,   170] train loss: 0.654
[24,   175] train loss: 0.653
[24,   180] train loss: 0.665
[24,   185] train loss: 0.650
[24,   190] train loss: 0.639
[24,   195] train loss: 0.647
[24,   200] train loss: 0.670
[24,   205] train loss: 0.662
[24,   210] train loss: 0.662
[24,   215] train loss: 0.645
[24,   220] train loss: 0.658
[24,   225] train loss: 0.658
[24,   230] train loss: 0.654
[24,   235] train loss: 0.629
[24,   240] train loss: 0.651
[24,   245] train loss: 0.674
[24,   250] train loss: 0.667
[24,   255] train loss: 0.654
[24,   260] train loss: 0.665
[24,   265] train loss: 0.640
[24,   270] train loss: 0.649
[24,   275] train loss: 0.653
[24,   280] train loss: 0.685
[24,   285] train loss: 0.650
[24,   290] train loss: 0.670
[24,   295] train loss: 0.658
[24,   300] train loss: 0.658
[24,   305] train loss: 0.654
[24,   310] train loss: 0.649
[24,   315] train loss: 0.662
[24,   320] train loss: 0.652
[24,   325] train loss: 0.648
[24,   330] train loss: 0.683
[24,   335] train loss: 0.668
[24,   340] train loss: 0.661
[24,   345] train loss: 0.640
[24,   350] train loss: 0.647
[24,   355] train loss: 0.645
[24,   360] train loss: 0.644
[24,   365] train loss: 0.628
[24,   370] train loss: 0.682
[24,   375] train loss: 0.667
[24,   380] train loss: 0.664
[24,   385] train loss: 0.639
[24,   390] train loss: 0.647
[24,   395] train loss: 0.668
[24,   400] train loss: 0.653
[24,   405] train loss: 0.671
[24,   410] train loss: 0.654
[24,   415] train loss: 0.663
[24,   420] train loss: 0.647
[24,   425] train loss: 0.637
[24,   430] train loss: 0.663
[24,   435] train loss: 0.670
[24,   440] train loss: 0.660
[24,   445] train loss: 0.645
[24,   450] train loss: 0.642
[24,   455] train loss: 0.647
[24,   460] train loss: 0.669
[24,   465] train loss: 0.636
[24,   470] train loss: 0.658
[24,   475] train loss: 0.665
[24,   480] train loss: 0.648
[24,   485] train loss: 0.666
[24,   490] train loss: 0.643
[24,   495] train loss: 0.666
[24,   500] train loss: 0.668
[24,   505] train loss: 0.686
[24,   510] train loss: 0.641
[24,   515] train loss: 0.665
[24,   520] train loss: 0.658
[24,   525] train loss: 0.637
[24,   530] train loss: 0.620
[24,   535] train loss: 0.653
[24,   540] train loss: 0.667
[24,   545] train loss: 0.666
[24,   550] train loss: 0.647
[24,   555] train loss: 0.653
[24,   560] train loss: 0.644
[24,   565] train loss: 0.655
[24,   570] train loss: 0.664
[24,   575] train loss: 0.641
[24,   580] train loss: 0.662
[24,   585] train loss: 0.670
[24,   590] train loss: 0.650
[24,   595] train loss: 0.646
[24,   600] train loss: 0.653
[24,   605] train loss: 0.641
[24,   610] train loss: 0.641
[24,   615] train loss: 0.671
[24,   620] train loss: 0.656
[24,   625] train loss: 0.667
[24,   630] train loss: 0.634
[24,   635] train loss: 0.663
[24,   640] train loss: 0.666
[24,   645] train loss: 0.647
[24,   650] train loss: 0.642
[24,   655] train loss: 0.632
Finished Training
[24,     5] test loss: 0.711
[24,    10] test loss: 0.679
[24,    15] test loss: 0.657
[24,    20] test loss: 0.640
[24,    25] test loss: 0.653
[24,    30] test loss: 0.631
[24,    35] test loss: 0.635
[24,    40] test loss: 0.668
[24,    45] test loss: 0.684
[24,    50] test loss: 0.660
[24,    55] test loss: 0.624
[24,    60] test loss: 0.639
[24,    65] test loss: 0.665
[24,    70] test loss: 0.641
[24,    75] test loss: 0.657
[24,    80] test loss: 0.677
[24,    85] test loss: 0.664
[24,    90] test loss: 0.703
[24,    95] test loss: 0.641
[24,   100] test loss: 0.693
[24,   105] test loss: 0.669
[24,   110] test loss: 0.658
[24,   115] test loss: 0.656
[24,   120] test loss: 0.665
[24,   125] test loss: 0.689
[24,   130] test loss: 0.653
[24,   135] test loss: 0.641
[24,   140] test loss: 0.645
[24,   145] test loss: 0.668
[24,   150] test loss: 0.666
[24,   155] test loss: 0.661
[24,   160] test loss: 0.666
[24,   165] test loss: 0.672
[24,   170] test loss: 0.672
[24,   175] test loss: 0.651
[24,   180] test loss: 0.625
[24,   185] test loss: 0.639
[24,   190] test loss: 0.654
[24,   195] test loss: 0.689
[24,   200] test loss: 0.659
[24,   205] test loss: 0.657
[24,   210] test loss: 0.675
[24,   215] test loss: 0.661
[24,   220] test loss: 0.669
-----------------------------------------------------------------------------------------
Micro-Precision: 0.31537118554115295, Macro-Precision: nan

Micro-Recall: 0.3512516915798187, Macro-Recall: nan

Micro-F1: 0.3323458135128021, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  23 | time: 160.41s | valid loss  0.66 | valid ppl     1.94
-----------------------------------------------------------------------------------------
[25,     5] train loss: 0.674
[25,    10] train loss: 0.635
[25,    15] train loss: 0.663
[25,    20] train loss: 0.650
[25,    25] train loss: 0.642
[25,    30] train loss: 0.637
[25,    35] train loss: 0.650
[25,    40] train loss: 0.651
[25,    45] train loss: 0.635
[25,    50] train loss: 0.639
[25,    55] train loss: 0.637
[25,    60] train loss: 0.646
[25,    65] train loss: 0.668
[25,    70] train loss: 0.668
[25,    75] train loss: 0.646
[25,    80] train loss: 0.635
[25,    85] train loss: 0.646
[25,    90] train loss: 0.662
[25,    95] train loss: 0.653
[25,   100] train loss: 0.651
[25,   105] train loss: 0.635
[25,   110] train loss: 0.637
[25,   115] train loss: 0.656
[25,   120] train loss: 0.651
[25,   125] train loss: 0.637
[25,   130] train loss: 0.672
[25,   135] train loss: 0.652
[25,   140] train loss: 0.648
[25,   145] train loss: 0.634
[25,   150] train loss: 0.659
[25,   155] train loss: 0.636
[25,   160] train loss: 0.666
[25,   165] train loss: 0.632
[25,   170] train loss: 0.655
[25,   175] train loss: 0.649
[25,   180] train loss: 0.633
[25,   185] train loss: 0.650
[25,   190] train loss: 0.651
[25,   195] train loss: 0.637
[25,   200] train loss: 0.663
[25,   205] train loss: 0.654
[25,   210] train loss: 0.657
[25,   215] train loss: 0.651
[25,   220] train loss: 0.657
[25,   225] train loss: 0.636
[25,   230] train loss: 0.628
[25,   235] train loss: 0.637
[25,   240] train loss: 0.661
[25,   245] train loss: 0.648
[25,   250] train loss: 0.639
[25,   255] train loss: 0.628
[25,   260] train loss: 0.647
[25,   265] train loss: 0.677
[25,   270] train loss: 0.632
[25,   275] train loss: 0.656
[25,   280] train loss: 0.679
[25,   285] train loss: 0.640
[25,   290] train loss: 0.650
[25,   295] train loss: 0.619
[25,   300] train loss: 0.621
[25,   305] train loss: 0.645
[25,   310] train loss: 0.664
[25,   315] train loss: 0.671
[25,   320] train loss: 0.667
[25,   325] train loss: 0.644
[25,   330] train loss: 0.640
[25,   335] train loss: 0.640
[25,   340] train loss: 0.656
[25,   345] train loss: 0.660
[25,   350] train loss: 0.650
[25,   355] train loss: 0.678
[25,   360] train loss: 0.677
[25,   365] train loss: 0.646
[25,   370] train loss: 0.652
[25,   375] train loss: 0.664
[25,   380] train loss: 0.650
[25,   385] train loss: 0.670
[25,   390] train loss: 0.666
[25,   395] train loss: 0.665
[25,   400] train loss: 0.657
[25,   405] train loss: 0.642
[25,   410] train loss: 0.678
[25,   415] train loss: 0.652
[25,   420] train loss: 0.632
[25,   425] train loss: 0.667
[25,   430] train loss: 0.646
[25,   435] train loss: 0.637
[25,   440] train loss: 0.652
[25,   445] train loss: 0.663
[25,   450] train loss: 0.676
[25,   455] train loss: 0.652
[25,   460] train loss: 0.633
[25,   465] train loss: 0.638
[25,   470] train loss: 0.666
[25,   475] train loss: 0.666
[25,   480] train loss: 0.667
[25,   485] train loss: 0.653
[25,   490] train loss: 0.637
[25,   495] train loss: 0.645
[25,   500] train loss: 0.634
[25,   505] train loss: 0.663
[25,   510] train loss: 0.688
[25,   515] train loss: 0.648
[25,   520] train loss: 0.661
[25,   525] train loss: 0.635
[25,   530] train loss: 0.642
[25,   535] train loss: 0.637
[25,   540] train loss: 0.646
[25,   545] train loss: 0.672
[25,   550] train loss: 0.642
[25,   555] train loss: 0.675
[25,   560] train loss: 0.637
[25,   565] train loss: 0.650
[25,   570] train loss: 0.677
[25,   575] train loss: 0.647
[25,   580] train loss: 0.652
[25,   585] train loss: 0.635
[25,   590] train loss: 0.643
[25,   595] train loss: 0.627
[25,   600] train loss: 0.669
[25,   605] train loss: 0.658
[25,   610] train loss: 0.662
[25,   615] train loss: 0.655
[25,   620] train loss: 0.666
[25,   625] train loss: 0.636
[25,   630] train loss: 0.655
[25,   635] train loss: 0.649
[25,   640] train loss: 0.645
[25,   645] train loss: 0.647
[25,   650] train loss: 0.637
[25,   655] train loss: 0.623
Finished Training
[25,     5] test loss: 0.676
[25,    10] test loss: 0.644
[25,    15] test loss: 0.688
[25,    20] test loss: 0.654
[25,    25] test loss: 0.638
[25,    30] test loss: 0.644
[25,    35] test loss: 0.653
[25,    40] test loss: 0.657
[25,    45] test loss: 0.658
[25,    50] test loss: 0.625
[25,    55] test loss: 0.662
[25,    60] test loss: 0.661
[25,    65] test loss: 0.657
[25,    70] test loss: 0.657
[25,    75] test loss: 0.670
[25,    80] test loss: 0.644
[25,    85] test loss: 0.668
[25,    90] test loss: 0.633
[25,    95] test loss: 0.655
[25,   100] test loss: 0.653
[25,   105] test loss: 0.653
[25,   110] test loss: 0.646
[25,   115] test loss: 0.649
[25,   120] test loss: 0.634
[25,   125] test loss: 0.661
[25,   130] test loss: 0.635
[25,   135] test loss: 0.651
[25,   140] test loss: 0.676
[25,   145] test loss: 0.680
[25,   150] test loss: 0.695
[25,   155] test loss: 0.667
[25,   160] test loss: 0.652
[25,   165] test loss: 0.636
[25,   170] test loss: 0.653
[25,   175] test loss: 0.683
[25,   180] test loss: 0.626
[25,   185] test loss: 0.634
[25,   190] test loss: 0.624
[25,   195] test loss: 0.665
[25,   200] test loss: 0.679
[25,   205] test loss: 0.665
[25,   210] test loss: 0.694
[25,   215] test loss: 0.684
[25,   220] test loss: 0.657
-----------------------------------------------------------------------------------------
Micro-Precision: 0.3189837336540222, Macro-Precision: nan

Micro-Recall: 0.34259000420570374, Macro-Recall: nan

Micro-F1: 0.33036571741104126, Macro-F1: nan

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  24 | time: 159.70s | valid loss  0.66 | valid ppl     1.93
-----------------------------------------------------------------------------------------
